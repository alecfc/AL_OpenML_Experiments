{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print (sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import pickle\n",
    "import seaborn as sn\n",
    "import sklearn as sk\n",
    "import xgboost\n",
    "import sklearn\n",
    "import openml\n",
    "\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from modAL.models import ActiveLearner, Committee\n",
    "from modAL.uncertainty import uncertainty_sampling, entropy_sampling\n",
    "from modAL.expected_error import expected_error_reduction\n",
    "from modAL.density import information_density\n",
    "from modAL.disagreement import vote_entropy_sampling, consensus_entropy_sampling, max_disagreement_sampling\n",
    "from modAL.utils.selection import multi_argmax, shuffled_argmax\n",
    "from numpy import trapz, log2\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import clone\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels, KERNEL_PARAMS\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.special import gammaln, factorial\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from openml.datasets import edit_dataset, fork_dataset, get_dataset\n",
    "\n",
    "# from pip command\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from copy import deepcopy\n",
    "import multiprocessing\n",
    "\n",
    "warnings.filterwarnings('ignore') # precision often has cases where there are no predictions for the minority class, which leads to zero-division. This keeps that warning from showing up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 of 4040 datasets...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>uploader</th>\n",
       "      <th>status</th>\n",
       "      <th>format</th>\n",
       "      <th>MajorityClassSize</th>\n",
       "      <th>MaxNominalAttDistinctValues</th>\n",
       "      <th>MinorityClassSize</th>\n",
       "      <th>NumberOfClasses</th>\n",
       "      <th>NumberOfFeatures</th>\n",
       "      <th>NumberOfInstances</th>\n",
       "      <th>NumberOfInstancesWithMissingValues</th>\n",
       "      <th>NumberOfMissingValues</th>\n",
       "      <th>NumberOfNumericFeatures</th>\n",
       "      <th>NumberOfSymbolicFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anneal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>684.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>22175.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>labor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>245.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>letter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>813.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>audiology</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>57.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>liver-disorders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>autos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>67.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>lymph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>balance-scale</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>288.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    did             name  version uploader  status format  MajorityClassSize  \\\n",
       "2     2           anneal        1        1  active   ARFF              684.0   \n",
       "3     3         kr-vs-kp        1        1  active   ARFF             1669.0   \n",
       "4     4            labor        1        1  active   ARFF               37.0   \n",
       "5     5       arrhythmia        1        1  active   ARFF              245.0   \n",
       "6     6           letter        1        1  active   ARFF              813.0   \n",
       "7     7        audiology        1        1  active   ARFF               57.0   \n",
       "8     8  liver-disorders        1        1  active   ARFF                NaN   \n",
       "9     9            autos        1        1  active   ARFF               67.0   \n",
       "10   10            lymph        1        1  active   ARFF               81.0   \n",
       "11   11    balance-scale        1        1  active   ARFF              288.0   \n",
       "\n",
       "    MaxNominalAttDistinctValues  MinorityClassSize  NumberOfClasses  \\\n",
       "2                           7.0                8.0              5.0   \n",
       "3                           3.0             1527.0              2.0   \n",
       "4                           3.0               20.0              2.0   \n",
       "5                          13.0                2.0             13.0   \n",
       "6                          26.0              734.0             26.0   \n",
       "7                          24.0                1.0             24.0   \n",
       "8                           NaN                NaN              0.0   \n",
       "9                          22.0                3.0              6.0   \n",
       "10                          8.0                2.0              4.0   \n",
       "11                          3.0               49.0              3.0   \n",
       "\n",
       "    NumberOfFeatures  NumberOfInstances  NumberOfInstancesWithMissingValues  \\\n",
       "2               39.0              898.0                               898.0   \n",
       "3               37.0             3196.0                                 0.0   \n",
       "4               17.0               57.0                                56.0   \n",
       "5              280.0              452.0                               384.0   \n",
       "6               17.0            20000.0                                 0.0   \n",
       "7               70.0              226.0                               222.0   \n",
       "8                6.0              345.0                                 0.0   \n",
       "9               26.0              205.0                                46.0   \n",
       "10              19.0              148.0                                 0.0   \n",
       "11               5.0              625.0                                 0.0   \n",
       "\n",
       "    NumberOfMissingValues  NumberOfNumericFeatures  NumberOfSymbolicFeatures  \n",
       "2                 22175.0                      6.0                      33.0  \n",
       "3                     0.0                      0.0                      37.0  \n",
       "4                   326.0                      8.0                       9.0  \n",
       "5                   408.0                    206.0                      74.0  \n",
       "6                     0.0                     16.0                       1.0  \n",
       "7                   317.0                      0.0                      70.0  \n",
       "8                     0.0                      6.0                       0.0  \n",
       "9                    59.0                     15.0                      11.0  \n",
       "10                    0.0                      3.0                      16.0  \n",
       "11                    0.0                      4.0                       1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openml_list = openml.datasets.list_datasets()  # returns a dict\n",
    "\n",
    "# Show a nice table with some key data properties\n",
    "datalist = pd.DataFrame.from_dict(openml_list, orient=\"index\")\n",
    "datalist = datalist[[\"did\", \"name\", \"NumberOfInstances\", \"NumberOfFeatures\", \"NumberOfClasses\"]]\n",
    "\n",
    "print(f\"First 10 of {len(datalist)} datasets...\")\n",
    "datalist.head(n=10)\n",
    "\n",
    "# The same can be done with lesser lines of code\n",
    "openml_df = openml.datasets.list_datasets(output_format=\"dataframe\")\n",
    "openml_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>name</th>\n",
       "      <th>NumberOfInstances</th>\n",
       "      <th>NumberOfFeatures</th>\n",
       "      <th>NumberOfClasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>credit-g</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    did      name  NumberOfInstances  NumberOfFeatures  NumberOfClasses\n",
       "31   31  credit-g             1000.0              21.0              2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist[datalist.NumberOfInstances > 10000].sort_values([\"NumberOfInstances\"]).head(n=20)\n",
    "\"\"\n",
    "datalist.query('name == \"credit-g\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is dataset 'credit-g', the target feature is 'class'\n",
      "URL: https://old.openml.org/data/v1/download/31/credit-g.arff\n",
      "**Author**: Dr. Hans Hofmann  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \n",
      "**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\n",
      "\n",
      "**German Credit dataset**  \n",
      "This dataset classifies people described by a set of attributes as good or bad credit risks.\n",
      "\n",
      "This dataset comes with a cost matrix: \n",
      "``` \n",
      "Good  Bad (predicted)  \n",
      "Good   0    1 (actual)  \n",
      "Bad    5    0  \n",
      "```\n",
      "\n",
      "It is worse to class a customer as good when they are ba\n"
     ]
    }
   ],
   "source": [
    "# This is done based on the dataset ID.\n",
    "dataset = openml.datasets.get_dataset(31) # Get credit dataset\n",
    "\n",
    "# Print a summary\n",
    "print(\n",
    "    f\"This is dataset '{dataset.name}', the target feature is \"\n",
    "    f\"'{dataset.default_target_attribute}'\"\n",
    ")\n",
    "print(f\"URL: {dataset.url}\")\n",
    "print(dataset.description[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  checking_status  duration                  credit_history  \\\n",
      "0              <0         6  critical/other existing credit   \n",
      "1        0<=X<200        48                   existing paid   \n",
      "2     no checking        12  critical/other existing credit   \n",
      "3              <0        42                   existing paid   \n",
      "4              <0        24              delayed previously   \n",
      "\n",
      "               purpose  credit_amount    savings_status employment  \\\n",
      "0             radio/tv         1169.0  no known savings        >=7   \n",
      "1             radio/tv         5951.0              <100     1<=X<4   \n",
      "2            education         2096.0              <100     4<=X<7   \n",
      "3  furniture/equipment         7882.0              <100     4<=X<7   \n",
      "4              new car         4870.0              <100     1<=X<4   \n",
      "\n",
      "   installment_commitment     personal_status other_parties  residence_since  \\\n",
      "0                       4         male single          none                4   \n",
      "1                       2  female div/dep/mar          none                2   \n",
      "2                       2         male single          none                3   \n",
      "3                       2         male single     guarantor                4   \n",
      "4                       3         male single          none                4   \n",
      "\n",
      "  property_magnitude  age other_payment_plans   housing  existing_credits  \\\n",
      "0        real estate   67                none       own                 2   \n",
      "1        real estate   22                none       own                 1   \n",
      "2        real estate   49                none       own                 1   \n",
      "3     life insurance   45                none  for free                 1   \n",
      "4  no known property   53                none  for free                 2   \n",
      "\n",
      "                  job  num_dependents own_telephone foreign_worker  \n",
      "0             skilled               1           yes            yes  \n",
      "1             skilled               1          none            yes  \n",
      "2  unskilled resident               2          none            yes  \n",
      "3             skilled               2          none            yes  \n",
      "4             skilled               2          none            yes  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   checking_status         1000 non-null   category\n",
      " 1   duration                1000 non-null   uint8   \n",
      " 2   credit_history          1000 non-null   category\n",
      " 3   purpose                 1000 non-null   category\n",
      " 4   credit_amount           1000 non-null   float64 \n",
      " 5   savings_status          1000 non-null   category\n",
      " 6   employment              1000 non-null   category\n",
      " 7   installment_commitment  1000 non-null   uint8   \n",
      " 8   personal_status         1000 non-null   category\n",
      " 9   other_parties           1000 non-null   category\n",
      " 10  residence_since         1000 non-null   uint8   \n",
      " 11  property_magnitude      1000 non-null   category\n",
      " 12  age                     1000 non-null   uint8   \n",
      " 13  other_payment_plans     1000 non-null   category\n",
      " 14  housing                 1000 non-null   category\n",
      " 15  existing_credits        1000 non-null   uint8   \n",
      " 16  job                     1000 non-null   category\n",
      " 17  num_dependents          1000 non-null   uint8   \n",
      " 18  own_telephone           1000 non-null   category\n",
      " 19  foreign_worker          1000 non-null   category\n",
      "dtypes: category(13), float64(1), uint8(6)\n",
      "memory usage: 26.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    target=dataset.default_target_attribute, dataset_format=\"dataframe\"\n",
    ")\n",
    "print(X.head())\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_openml_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6f3be56f4ab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m run_openml_test(data=X,k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n\u001b[0m\u001b[0;32m      2\u001b[0m              \u001b[0mml_method_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_sep_method_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mal_method_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqbc_learners_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_qbc_learners_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_openml_test' is not defined"
     ]
    }
   ],
   "source": [
    "run_openml_test(data=X,k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a density-weighted sampling method given a classifier and a candidate pool of instances to be sampled. \n",
    "# By default only one instance is sampled. Multi-instance sampling not supported.\n",
    "def density_sampling(classifier, X_pool, n_instances: int = 1, **predict_proba_kwargs):\n",
    "    density = information_density(X_pool, \"cosine\") # cosine or euclidean\n",
    "    density = np.ones(len(density)) - density\n",
    "    \n",
    "    try:\n",
    "        classwise_uncertainty = classifier.predict_proba(X_pool, **predict_proba_kwargs)\n",
    "    except NotFittedError:\n",
    "        return np.ones(shape=(X.shape[0], ))\n",
    "\n",
    "    # for each point, select the maximum uncertainty\n",
    "    uncertainty = 1 - np.max(classwise_uncertainty, axis=1)\n",
    "    dense_informative = np.multiply(uncertainty, density)\n",
    "\n",
    "    query_idx = shuffled_argmax(dense_informative, n_instances=n_instances)\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty method which allows for the creation of committee for QBC sampling while using the same style of AL selection as other methods.\n",
    "def qbc_sampling(classifier, X_pool):\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a random sampling strategy given a classifier and a candidate pool of instances to be sampled.\n",
    "def random_sampling(classifier, X_pool):\n",
    "    n_samples = len(X_pool)\n",
    "    query_idx = np.random.choice(range(n_samples))\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for the different versions of PAL\n",
    "\n",
    "def euler_beta(a, axis=1):\n",
    "    \"\"\"\n",
    "    Represents Euler beta function: B(a(i)) = Gamma(a(i,1))*...*Gamma(a_n)/Gamma(a(i,1)+...+a(i,n))\n",
    "    Parameters\n",
    "    ----------\n",
    "    a: array-like, shape (m, n)\n",
    "        Vectors to evaluated.\n",
    "    axis: int\n",
    "        Determines along which axis the Euler beta function is computed.\n",
    "    Returns\n",
    "    -------\n",
    "    result: array-like, shape (m)\n",
    "        Euler beta function results [B(a(0)), ..., B(a(m))\n",
    "    \"\"\"\n",
    "    return np.exp(np.sum(gammaln(a), axis=axis)-gammaln(np.sum(a, axis=axis)))\n",
    "\n",
    "def multinomial_coefficient(a, axis=1):\n",
    "    \"\"\"\n",
    "    Computes Multinomial coefficient: Mult(a(i)) = (a(i,1)+...+a(i,n))!/(a(i,1)!...a(i,n)!)\n",
    "    Parameters\n",
    "    ----------\n",
    "    a: array-like, shape (m, n)\n",
    "        Vectors to evaluated.\n",
    "    axis: int\n",
    "        Determines along which axis the Euler beta function is computed.\n",
    "    Returns\n",
    "    -------\n",
    "    result: array-like, shape (m)\n",
    "        Multinomial coefficients [Mult(a(0)), ..., Mult(a(m))\n",
    "    \"\"\"\n",
    "    return factorial(np.sum(a, axis=axis))/np.prod(factorial(a), axis=axis)\n",
    "\n",
    "def gen_l_vec_list(m_approx, n_classes):\n",
    "    \"\"\"\n",
    "    Creates all possible class labeling vectors for given number of hypothetically acquired labels and given number of\n",
    "    classes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    m_approx: int\n",
    "        Number of hypothetically acquired labels..\n",
    "    n_classes: int,\n",
    "        Number of classes\n",
    "    Returns\n",
    "    -------\n",
    "    label_vec_list: array-like, shape = [n_label_vectors, n_classes]\n",
    "        All possible label vectors for given parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    label_vec_list = [[]]\n",
    "    label_vec_res = np.arange(m_approx + 1)\n",
    "    for i in range(n_classes - 1):\n",
    "        new_label_vec_list = []\n",
    "        for labelVec in label_vec_list:\n",
    "            for newLabel in label_vec_res[label_vec_res - (m_approx - sum(labelVec)) <= 1.e-10]:\n",
    "                new_label_vec_list.append(labelVec + [newLabel])\n",
    "        label_vec_list = new_label_vec_list\n",
    "\n",
    "    new_label_vec_list = []\n",
    "    for labelVec in label_vec_list:\n",
    "        new_label_vec_list.append(labelVec + [m_approx - sum(labelVec)])\n",
    "    label_vec_list = np.array(new_label_vec_list, int)\n",
    "\n",
    "    return label_vec_list\n",
    "\n",
    "def _validate_data(X_cand, return_utilities, batch_size,\n",
    "                   random_state, reset=True, **check_X_cand_params):\n",
    "    \"\"\"Validate input data and set or check the `n_features_in_` attribute.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_cand: array-like, shape (n_candidates, n_features)\n",
    "        Candidate samples.\n",
    "    batch_size : int,\n",
    "        The number of samples to be selected in one AL cycle.\n",
    "    return_utilities : bool,\n",
    "        If true, also return the utilities based on the query strategy.\n",
    "    random_state : numeric | np.random.RandomState, optional\n",
    "        The random state to use.\n",
    "    reset : bool, default=True\n",
    "        Whether to reset the `n_features_in_` attribute.\n",
    "        If False, the input will be checked for consistency with data\n",
    "        provided when reset was last True.\n",
    "    **check_X_cand_params : kwargs\n",
    "        Parameters passed to :func:`sk.utils.check_array`.\n",
    "    Returns\n",
    "    -------\n",
    "    X_cand: np.ndarray, shape (n_candidates, n_features)\n",
    "        Checked candidate samples\n",
    "    batch_size : int\n",
    "        Checked number of samples to be selected in one AL cycle.\n",
    "    return_utilities : bool,\n",
    "        Checked boolean value of `return_utilities`.\n",
    "    random_state : np.random.RandomState,\n",
    "        Checked random state to use.\n",
    "    \"\"\"\n",
    "    # Check candidate instances.\n",
    "    X_cand = check_array(X_cand, **check_X_cand_params)\n",
    "\n",
    "    # Check return_utilities.\n",
    "    check_scalar(return_utilities, 'return_utilities', bool)\n",
    "\n",
    "    # Check batch size.\n",
    "    check_scalar(batch_size, target_type=int, name='batch_size',\n",
    "                 min_val=1)\n",
    "    batch_size = batch_size\n",
    "    if len(X_cand) < batch_size:\n",
    "        warnings.warn(\n",
    "            \"'batch_size={}' is larger than number of candidate samples \"\n",
    "            \"in 'X_cand'. Instead, 'batch_size={}' was set \".format(\n",
    "                batch_size, len(X_cand)))\n",
    "        batch_size = len(X_cand)\n",
    "\n",
    "    # Check random state.\n",
    "    random_state = check_random_state(random_state=random_state,\n",
    "                                      seed_multiplier=len(X_cand))\n",
    "\n",
    "    return X_cand, return_utilities, batch_size, random_state\n",
    "\n",
    "def check_scalar(x, name, target_type, min_inclusive=True, max_inclusive=True,\n",
    "                 min_val=None, max_val=None):\n",
    "    \"\"\"Validate scalar parameters type and value.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : object\n",
    "        The scalar parameter to validate.\n",
    "    name : str\n",
    "        The name of the parameter to be printed in error messages.\n",
    "    target_type : type or tuple\n",
    "        Acceptable data types for the parameter.\n",
    "    min_val : float or int, optional (default=None)\n",
    "        The minimum valid value the parameter can take. If None (default) it\n",
    "        is implied that the parameter does not have a lower bound.\n",
    "    min_inclusive : bool, optional (default=True)\n",
    "        If true, the minimum valid value is inclusive, otherwise exclusive.\n",
    "    max_val : float or int, optional (default=None)\n",
    "        The maximum valid value the parameter can take. If None (default) it\n",
    "        is implied that the parameter does not have an upper bound.\n",
    "    max_inclusive : bool, optional (default=True)\n",
    "        If true, the maximum valid value is inclusive, otherwise exclusive.\n",
    "    Raises\n",
    "    -------\n",
    "    TypeError\n",
    "        If the parameter's type does not match the desired type.\n",
    "    ValueError\n",
    "        If the parameter's value violates the given bounds.\n",
    "    \"\"\"\n",
    "    if not isinstance(x, target_type):\n",
    "        raise TypeError('`{}` must be an instance of {}, not {}.'\n",
    "                        .format(name, target_type, type(x)))\n",
    "    if min_inclusive:\n",
    "        if min_val is not None and x < min_val:\n",
    "            raise ValueError('`{}`= {}, must be >= '\n",
    "                             '{}.'.format(name, x, min_val))\n",
    "    else:\n",
    "        if min_val is not None and x <= min_val:\n",
    "            raise ValueError('`{}`= {}, must be > '\n",
    "                             '{}.'.format(name, x, min_val))\n",
    "\n",
    "    if max_inclusive:\n",
    "        if max_val is not None and x > max_val:\n",
    "            raise ValueError('`{}`= {}, must be <= '\n",
    "                             '{}.'.format(name, x, max_val))\n",
    "    else:\n",
    "        if max_val is not None and x >= max_val:\n",
    "            raise ValueError('`{}`= {}, must be < '\n",
    "                             '{}.'.format(name, x, max_val))\n",
    "            \n",
    "def check_random_state(random_state, seed_multiplier=None):\n",
    "    \"\"\"Check validity of the given random state.\n",
    "    Parameters\n",
    "    ----------\n",
    "    random_state : None | int | instance of RandomState\n",
    "        If random_state is None, return the RandomState singleton used by\n",
    "        np.random.\n",
    "        If random_state is an int, return a new RandomState.\n",
    "        If random_state is already a RandomState instance, return it.\n",
    "        Otherwise raise ValueError.\n",
    "    seed_multiplier : None | int, optional (default=None)\n",
    "        If the random_state and seed_multiplier are not None, draw a new int\n",
    "        from the random state, multiply it with the multiplier, and use the\n",
    "        product as the seed of a new random state.\n",
    "    Returns\n",
    "    -------\n",
    "    random_state: instance of RandomState\n",
    "        The validated random state.\n",
    "    \"\"\"\n",
    "    if random_state is None or seed_multiplier is None:\n",
    "        return sk.utils.check_random_state(random_state)\n",
    "\n",
    "    check_scalar(seed_multiplier, name='seed_multiplier', target_type=int,\n",
    "                 min_val=1)\n",
    "    random_state = copy.deepcopy(random_state)\n",
    "    random_state = sk.utils.check_random_state(random_state)\n",
    "\n",
    "    seed = (random_state.randint(1, 2**31) * seed_multiplier) % (2**31)\n",
    "    return np.random.RandomState(seed)\n",
    "\n",
    "def _cost_reduction(k_vec_list, C=None, m_max=2, prior=1.e-3):\n",
    "    \"\"\"Calculate the expected cost reduction.\n",
    "    Calculate the expected cost reduction for given maximum number of\n",
    "    hypothetically acquired labels, observed labels and cost matrix.\n",
    "    Parameters\n",
    "    ----------\n",
    "    k_vec_list: array-like, shape (n_samples, n_classes)\n",
    "        Observed class labels.\n",
    "    C: array-like, shape = (n_classes, n_classes)\n",
    "        Cost matrix.\n",
    "    m_max: int\n",
    "        Maximal number of hypothetically acquired labels.\n",
    "    prior : float | array-like, shape (n_classes)\n",
    "       Prior value for each class.\n",
    "    Returns\n",
    "    -------\n",
    "    expected_cost_reduction: array-like, shape (n_samples)\n",
    "        Expected cost reduction for given parameters.\n",
    "    \"\"\"\n",
    "    # Check if 'prior' is valid\n",
    "    check_scalar(prior, 'prior', (float, int),\n",
    "                 min_inclusive=False, min_val=0)\n",
    "\n",
    "    # Check if 'm_max' is valid\n",
    "    check_scalar(m_max, 'm_max', int, min_val=1)\n",
    "\n",
    "    n_classes = len(k_vec_list[0])\n",
    "    n_samples = len(k_vec_list)\n",
    "\n",
    "    # check cost matrix\n",
    "    C = 1 - np.eye(n_classes) if C is None else np.asarray(C)\n",
    "\n",
    "    # generate labelling vectors for all possible m values\n",
    "    l_vec_list = np.vstack([_gen_l_vec_list(m, n_classes)\n",
    "                            for m in range(m_max + 1)])\n",
    "    m_list = np.sum(l_vec_list, axis=1)\n",
    "    n_l_vecs = len(l_vec_list)\n",
    "\n",
    "    # compute optimal cost-sensitive decision for all combination of k-vectors\n",
    "    # and l-vectors\n",
    "    tile = np.tile(k_vec_list, (n_l_vecs, 1, 1))\n",
    "    k_l_vec_list = np.swapaxes(tile, 0, 1) + l_vec_list\n",
    "    y_hats = np.argmin(k_l_vec_list @ C, axis=2)\n",
    "\n",
    "    # add prior to k-vectors\n",
    "    prior = prior * np.ones(n_classes)\n",
    "    k_vec_list = np.asarray(k_vec_list) + prior\n",
    "\n",
    "    # all combination of k-, l-, and prediction indicator vectors\n",
    "    combs = [k_vec_list, l_vec_list, np.eye(n_classes)]\n",
    "    combs = np.asarray([list(elem)\n",
    "                        for elem in list(itertools.product(*combs))])\n",
    "\n",
    "    # three factors of the closed form solution\n",
    "    factor_1 = 1 / euler_beta(k_vec_list)\n",
    "    factor_2 = multinomial(l_vec_list)\n",
    "    factor_3 = euler_beta(np.sum(combs, axis=1)).reshape(n_samples, n_l_vecs,\n",
    "                                                         n_classes)\n",
    "\n",
    "    # expected classification cost for each m\n",
    "    m_sums = np.asarray(\n",
    "        [factor_1[k_idx]\n",
    "         * np.bincount(m_list, factor_2 * [C[:, y_hats[k_idx, l_idx]]\n",
    "                                           @ factor_3[k_idx, l_idx]\n",
    "                                           for l_idx in range(n_l_vecs)])\n",
    "         for k_idx in range(n_samples)]\n",
    "    )\n",
    "\n",
    "    # compute classification cost reduction as difference\n",
    "    gains = np.zeros((n_samples, m_max)) + m_sums[:, 0].reshape(-1, 1)\n",
    "    gains -= m_sums[:, 1:]\n",
    "\n",
    "    # normalize  cost reduction by number of hypothetical label acquisitions\n",
    "    gains /= np.arange(1, m_max + 1)\n",
    "\n",
    "    return np.max(gains, axis=1)\n",
    "\n",
    "def simple_batch(\n",
    "        utilities, random_state, batch_size=1, return_utilities=False):\n",
    "    \"\"\"Generates a batch by selecting the highest values in the 'utilities'.\n",
    "    The returned utilities will be an 2D-array with the shape batch_size x\n",
    "    len(utilities), filled the given utilities but set the n-th highest values\n",
    "    in the n-th row to np.nan.\n",
    "    Parameters\n",
    "    ----------\n",
    "    utilities : np.ndarray\n",
    "        The utilities to be used to create the batch.\n",
    "    random_state : numeric | np.random.RandomState\n",
    "        The random state to use.\n",
    "    batch_size : int, optional (default=1)\n",
    "        The number of samples to be selected in one AL cycle.\n",
    "    return_utilities : bool (default=False)\n",
    "        If True, the utilities are returned.\n",
    "    Returns\n",
    "    -------\n",
    "    best_indices : np.ndarray, shape (batch_size)\n",
    "        The index of the batch instance.\n",
    "    batch_utilities : np.ndarray,  shape (batch_size, len(utilities))\n",
    "        The utilities of the batch (if return_utilities=True).\n",
    "    \"\"\"\n",
    "    # validation\n",
    "    utilities = check_array(utilities, ensure_2d=False, dtype=float)\n",
    "    if batch_size == 'adaptive':\n",
    "        batch_size = 1\n",
    "    check_scalar(batch_size, target_type=int, name='batch_size',\n",
    "                 min_val=1)\n",
    "    if len(utilities) < batch_size:\n",
    "        warnings.warn(\n",
    "            \"'batch_size={}' is larger than number of candidate samples \"\n",
    "            \"in 'utilities'. Instead, 'batch_size={}' was set.\".format(\n",
    "                batch_size, len(utilities)))\n",
    "        batch_size = len(utilities)\n",
    "    # generate batch\n",
    "    batch_utilities = np.empty((batch_size, len(utilities)))\n",
    "    best_indices = np.empty(batch_size, dtype=int)\n",
    "    for i in range(batch_size):\n",
    "        best_indices[i] = rand_argmax(\n",
    "            [utilities], axis=1, random_state=random_state)\n",
    "        batch_utilities[i] = utilities\n",
    "        utilities[best_indices[i]] = np.nan\n",
    "    # Check whether utilities are to be returned.\n",
    "    if return_utilities:\n",
    "        return best_indices, batch_utilities\n",
    "    else:\n",
    "        return best_indices\n",
    "    \n",
    "# def predict_freq(classifier, X, classes):\n",
    "#     \"\"\"Return class frequency estimates for the input data X.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X : array-like, shape (n_samples, n_features)\n",
    "#         Input samples.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     F : array-like, shape (n_samples, classes)\n",
    "#         The class frequency estimates of the input samples. Classes are\n",
    "#         ordered according to classes_.\n",
    "#     \"\"\"\n",
    "# #     check_is_fitted(classifier)\n",
    "#     X = check_array(X)\n",
    "#     classifier._check_n_features(X, reset=False)\n",
    "    \n",
    "#     # Counts number of votes per class label for each sample.\n",
    "#     V = compute_vote_vectors(y=y, w=sample_weight,\n",
    "#                              classes=np.arange(len(self.classes_)))\n",
    "\n",
    "#     # Stores responsibility for every given sample of training set.\n",
    "#     R = self.mixture_model_.predict_proba(X)\n",
    "\n",
    "#     # Stores class frequency estimates per component.\n",
    "#     self.F_components_ = R.T @ V\n",
    "    \n",
    "    \n",
    "#     if np.sum(classifier.F_components_) > 0:\n",
    "#         if classifier.weight_mode == 'similarities':\n",
    "#             S = np.exp(-np.array(\n",
    "#                 [cdist(X, [self.mixture_model_.means_[j]],\n",
    "#                        metric='mahalanobis',\n",
    "#                        VI=classifiermixture_model_.precisions_[j]).ravel()\n",
    "#                  for j in range(classifier.mixture_model_.n_components)])).T\n",
    "#         else:\n",
    "#             S = classifier.mixture_model_.predict_proba(X)\n",
    "#         F = S @ classifier.F_components_\n",
    "#     else:\n",
    "#         F = np.zeros((len(X), len(classifier.classes_)))\n",
    "#     return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating gain used by PAL sampling (before weighting by frequency estimates)\n",
    "def pal_gain(K_c, m_max=2, alpha_c=1):\n",
    "    \"\"\"\n",
    "    Calculates the expected performance gains given a maximal number of hypothetically acquired labels,\n",
    "    the observed kernel frequency estimates and prior for the Dirichlet distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    K_c: array-like, shape (n_samples, n_classes)\n",
    "        Observed kernel frequency estimates of the candidate samples.\n",
    "    m_max: int, optional (default=2)\n",
    "        Maximal number of hypothetically acquired labels.\n",
    "    alpha_c : int | array-like, shape (n_classes), optional (default=1)\n",
    "        Prior probabilities for the Dirichlet distribution.\n",
    "        Default is 1 for all classes.\n",
    "    Returns\n",
    "    -------\n",
    "    gains: array-like, shape (n_samples)\n",
    "        Expected performance gains for given parameters.\n",
    "    \"\"\"\n",
    "    n_classes = len(K_c[0])\n",
    "    n_samples = len(K_c)\n",
    "\n",
    "    # uniform risk matrix\n",
    "    R = 1 - np.eye(n_classes)\n",
    "\n",
    "    # generate labeling vectors for all possible m values\n",
    "    l_vec_list = np.vstack([gen_l_vec_list(m, n_classes) for m in range(m_max + 1)])\n",
    "    m_list = np.sum(l_vec_list, axis=1)\n",
    "    n_l_vecs = len(l_vec_list)\n",
    "\n",
    "    # compute optimal decision for all combination of k- and l-vectors\n",
    "    k_l_vec_list = np.swapaxes(np.tile(K_c, (n_l_vecs, 1, 1)), 0, 1) + l_vec_list\n",
    "    y_hats = np.argmin(k_l_vec_list @ R, axis=2)\n",
    "\n",
    "    # add prior_classes to k-vectors\n",
    "    alpha_c = alpha_c * np.ones(n_classes)\n",
    "    K_c = np.asarray(K_c) + alpha_c\n",
    "\n",
    "    # all combination of k-, l-, and prediction indicator vectors\n",
    "    combs = [K_c, l_vec_list, np.eye(n_classes)]\n",
    "    combs = np.asarray([list(elem) for elem in list(itertools.product(*combs))])\n",
    "\n",
    "    # three factors of the closed form solution\n",
    "    factor_1 = 1 / euler_beta(K_c)\n",
    "    factor_2 = multinomial_coefficient(l_vec_list)\n",
    "    factor_3 = euler_beta(np.sum(combs, axis=1)).reshape(n_samples, n_l_vecs, n_classes)\n",
    "\n",
    "    # expected risk for each m\n",
    "    m_sums = np.asarray(\n",
    "        [factor_1[k_idx] * np.bincount(m_list, factor_2 * [R[:, y_hats[k_idx, l_idx]] @ factor_3[k_idx, l_idx]\n",
    "                                                           for l_idx in range(n_l_vecs)]) for k_idx in\n",
    "         range(n_samples)])\n",
    "\n",
    "    # compute performance gains as risk reductions\n",
    "    gains = np.zeros((n_samples, m_max)) + m_sums[:, 0].reshape(-1, 1)\n",
    "    gains -= m_sums[:, 1:]\n",
    "\n",
    "    # normalize performance gains by number of hypothetical label acquisitions\n",
    "    gains /= np.arange(1, m_max + 1)\n",
    "\n",
    "    return np.max(gains, axis=1)\n",
    "\n",
    "# Method used by PAL for computing score for all candidate instances in pool\n",
    "def compute_pal_scores(X_pool, n_classes, labeled_instances, labels, kernel, priors):\n",
    "        \"\"\"Compute score for each unlabeled sample. Score is to be maximized.\n",
    "        Parameters\n",
    "        ----------\n",
    "        unlabeled_indices: array-like, shape (n_unlabeled_samples)\n",
    "        Returns\n",
    "        -------\n",
    "        scores: array-like, shape (n_unlabeled_samples)\n",
    "            Score of each unlabeled sample.\n",
    "        \"\"\"\n",
    "        Z = np.eye(n_classes)[labels]\n",
    "\n",
    "        K_x = kernel[:, :len(labeled_instances)] @ Z\n",
    "        K_c = K_x[len(labeled_instances):]\n",
    "\n",
    "        # calculate loss reduction for each unlabeled sample\n",
    "        gains = pal_gain(K_c=K_c, alpha_c = priors)\n",
    "        \n",
    "        densities = np.sum(kernel, axis=1)\n",
    "        gains *= densities[len(labeled_instances):]\n",
    "\n",
    "        return gains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating gain used by xPAL sampling (before weighting by frequency estimates)\n",
    "def xpal_gain(K_c, K_x=None, S=None, alpha_x=1, alpha_c=1):\n",
    "    \"\"\"\n",
    "    Computes the expected probabilistic gain.\n",
    "    Parameters\n",
    "    ----------\n",
    "    K_c: array-like, shape (n_candidate_samples, n_classes)\n",
    "        Kernel frequency estimate vectors of the candidate samples.\n",
    "    K_x: array-like, shape (n_evaluation_samples, n_classes), optional (default=K_c))\n",
    "        Kernel frequency estimate vectors of the evaluation samples.\n",
    "    S: array-like, shape (n_candidate_samples, n_evaluation_samples), optional (default=np.eye(n_candidate_samples))\n",
    "        Similarities between all pairs of candidate and evaluation samples\n",
    "    alpha_x: array-like, shape (n_classes)\n",
    "        Prior probabilities for the Dirichlet distribution of the samples in the evaluation set.\n",
    "        Default is 1 for all classes.\n",
    "    alpha_c: float | array-like, shape (n_classes)\n",
    "        Prior probabilities for the Dirichlet distribution of the candidate samples.\n",
    "        Default is 1 for all classes.\n",
    "    Returns\n",
    "    -------\n",
    "    gains: numpy.ndarray, shape (n_candidate_samples)\n",
    "        Computed expected gain for each candidate sample.\n",
    "    \"\"\"\n",
    "    # check kernel frequency estimates of candidate samples\n",
    "    K_c = check_array(K_c)\n",
    "    n_candidate_samples = K_c.shape[0]\n",
    "    n_classes = K_c.shape[1]\n",
    "\n",
    "    # check kernel frequency estimates of evaluation samples\n",
    "    K_x = K_c if K_x is None else check_array(K_x)\n",
    "    n_evaluation_samples = K_x.shape[0]\n",
    "    if n_classes != K_x.shape[1]:\n",
    "        raise ValueError(\"'K_x' and 'K_c' must have one column per class\")\n",
    "\n",
    "    # check similarity matrix\n",
    "    S = np.eye(n_candidate_samples) if S is None else check_array(S)\n",
    "    if S.shape[0] != n_candidate_samples or S.shape[1] != n_evaluation_samples:\n",
    "        raise ValueError(\"'S' must have the shape (n_candidate_samples, n_evaluation_samples)\")\n",
    "\n",
    "    # check prior parameters\n",
    "    if hasattr(alpha_c, \"__len__\") and len(alpha_c) != n_classes:\n",
    "        raise ValueError(\"'alpha_c' must be either a float > 0 or array-like with shape (n_classes)\")\n",
    "    if hasattr(alpha_x, \"__len__\") and len(alpha_x) != n_classes:\n",
    "        raise ValueError(\"'alpha_x' must be either a float > 0 or array-like with shape (n_classes)\")\n",
    "\n",
    "    # uniform risk matrix\n",
    "    R = 1 - np.eye(n_classes)\n",
    "\n",
    "    # model future hypothetical labels\n",
    "    l_vecs = np.eye(n_classes, dtype=int)\n",
    "\n",
    "    # compute possible risk differences\n",
    "    class_vector = np.arange(n_classes, dtype=int)\n",
    "    R_diff = np.array([[R[:, y_hat] - R[:, y_hat_l] for y_hat_l in class_vector] for y_hat in class_vector])\n",
    "\n",
    "    # compute current error per evaluation sample and class\n",
    "    R_x = K_x @ R\n",
    "\n",
    "    # compute current predictions\n",
    "    y_hat = np.argmin(R_x, axis=1)\n",
    "\n",
    "    # compute required labels per class to flip decision\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        D_x = np.nanmin(np.divide(R_x - np.min(R_x, axis=1, keepdims=True), R[:, y_hat].T), axis=1)\n",
    "        D_x = np.tile(D_x, (len(S), 1))\n",
    "\n",
    "    # indicates where a decision flip can be reached\n",
    "    I = D_x - S < 0\n",
    "    # print('#decision_flips: {}'.format(np.sum(I)))\n",
    "\n",
    "    # compute normalization constants per candidate sample\n",
    "    K_c_alpha_c_norm = K_c + alpha_c\n",
    "    K_c_alpha_c_norm /= K_c_alpha_c_norm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # stores gain per candidate sample\n",
    "    gains = np.zeros(n_candidate_samples)\n",
    "\n",
    "    target_weight = 100\n",
    "    non_target_weight = 0.05\n",
    "    \n",
    "    # compute gain for each candidate sample\n",
    "    flip_indices = np.argwhere(np.sum(I, axis=1) > 0)[:, 0]\n",
    "    for ik_c in flip_indices:\n",
    "        for l_idx, l_vec in enumerate(l_vecs):\n",
    "            if l_vec[0] == 0:\n",
    "                weight = non_target_weight\n",
    "            else:\n",
    "                weight = target_weight\n",
    "            \n",
    "            K_l = (S[ik_c, I[ik_c]] * l_vec[:, np.newaxis]).T\n",
    "            K_new = K_x[I[ik_c]] + K_l\n",
    "            y_hat_l = np.argmin(K_new @ R, axis=1)\n",
    "            K_new += alpha_x\n",
    "            K_new /= np.sum(K_new, axis=1, keepdims=True)\n",
    "            gains[ik_c] += K_c_alpha_c_norm[ik_c, l_idx] * np.sum(K_new * R_diff[y_hat[I[ik_c]], y_hat_l])\n",
    "            \n",
    "    gains /= n_evaluation_samples\n",
    "    \n",
    "    return gains\n",
    "\n",
    "# Method used by xPAL for computing score for all candidate instances in pool\n",
    "def compute_xpal_scores(X_pool, n_classes, labeled_instances, labels, kernel, priors):\n",
    "    \"\"\"Compute score for each unlabeled sample. Score is to be maximized.\n",
    "    Parameters\n",
    "    ----------\n",
    "    unlabeled_indices: array-like, shape (n_unlabeled_samples)\n",
    "    Returns\n",
    "    -------\n",
    "    scores: array-like, shape (n_unlabeled_samples)\n",
    "        Score of each unlabeled sample.\n",
    "    \"\"\"\n",
    "    # compute frequency estimates for evaluation set (K_x) and candidate set (K_c)\n",
    "    Z = np.eye(n_classes)[labels]\n",
    "\n",
    "    K_x = kernel[:, :len(labeled_instances)] @ Z\n",
    "    K_c = K_x[len(labeled_instances):]\n",
    "\n",
    "    # calculate loss reduction for each unlabeled sample\n",
    "    gains = xpal_gain(K_c=K_c, K_x = K_x, S = kernel[len(labeled_instances):], alpha_x = priors, alpha_c = priors) # S = kernel[len(labeled_instances)] or S= kernel\n",
    "\n",
    "    return gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_openml_test(datak_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a PAL sampling method given a classifier and a candidate pool of instances to be sampled\n",
    "def pal_sampling(classifier, X_pool, n_classes, labeled_instances, labels, kernel, priors):\n",
    "    scores = compute_pal_scores(X_pool, n_classes, labeled_instances, labels, kernel, priors)\n",
    "    query_idx = shuffled_argmax(scores, n_instances=1)\n",
    "    return query_idx, X_pool[query_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a xPAL sampling method given a classifier and a candidate pool of instances to be sampled\n",
    "def xpal_sampling(classifier, X_pool, n_classes, labeled_instances, labels, kernel, priors):\n",
    "    scores = compute_xpal_scores(X_pool, n_classes, labeled_instances, labels, kernel, priors)\n",
    "    query_idx = shuffled_argmax(scores, n_instances=1)\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switcher for selecting the desired classifier\n",
    "ML_switcher = {\n",
    "        1: LogisticRegression(solver='liblinear', n_jobs = -1),\n",
    "        2: RandomForestClassifier(n_jobs = -1),\n",
    "        3: xgboost.XGBClassifier(booster=\"dart\", eval_metric = 'error', use_label_encoder=False, n_jobs = -1),\n",
    "        4: DecisionTreeClassifier(random_state=None),\n",
    "        5: SVC(kernel='linear', probability=True)\n",
    "}\n",
    "\n",
    "# Switcher for selecting the desired AL method\n",
    "AL_switcher = {\n",
    "        1: random_sampling,\n",
    "        2: uncertainty_sampling,\n",
    "        3: density_sampling,\n",
    "        4: expected_error_reduction,\n",
    "        5: qbc_sampling,\n",
    "        6: pal_sampling,\n",
    "        7: xpal_sampling\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base definitions of all test settings. These are set with new values when calling the run_test method (or set_settings method).\n",
    "\n",
    "# Ideally will have at least 50 repetitions of validation of one method to get a good idea of performance. repetitions = K * EXECUTIONS\n",
    "K = 5 # number of folds for validation\n",
    "EXECUTIONS = 10 # number of executions of k-fold validation\n",
    "\n",
    "# Number of queries per round of learning. The main testing loops in run_test could be adapted to not be static. E.g. until convergence, or some other stopping criterion. \n",
    "# However, for evaluation it is easier if all methods are tested with the same number of queries (requirement of Area Under the Learning Curve measure (ALC)).\n",
    "# Performance is evaluated after each instance is queried and added to the training pool.\n",
    "N_QUERIES = 45\n",
    "\n",
    "# size of initialization set. Needs to be at least the # classes, but more if QBC used.\n",
    "INITIALIZATION_SET = 10\n",
    "\n",
    "# Whether to train/evaluate only on the summarized trajectories, ele all instances of each trajectory are used for training.\n",
    "TRAIN_ON_SUM = True\n",
    "\n",
    "# Whether separte classifiers should be used for querying and classifying (producer/consumer respectively)\n",
    "# *note, for QBC should petty much always use separate model. Really doesn't make sense not to.\n",
    "SEPARATE_CLASSIFIER = False\n",
    "\n",
    "# Classifier to be used:\n",
    "# 1 = logistic regression, 2 = Random Forest, 3 = XGBoost, 4 = Decision Tree, 5 = SVM (linear version)\n",
    "ML_METHOD = 3\n",
    "ML_SEP_METHOD = 3 # only relevant if using separate classifier as query producer. Overridden when using QBC\n",
    "\n",
    "# Active learning approach to be used:\n",
    "# 1 = random sampling, 2 = uncertainty sampling, 3 = density-weighted sampling, 4 = EER, 5 = QBC, 6 = PAL, 7 = XPAL\n",
    "AL_METHOD = 6\n",
    "\n",
    "# Specific learners used for the committee in QBC\n",
    "QBC_LEARNERS = [2,3,5]\n",
    "\n",
    "# The number of learners of each classifier type specified by QBC_LEARNERS to be used in QBC\n",
    "N_QBC_LEARNERS = 3\n",
    "\n",
    "# Selection of QBC disagreement measure\n",
    "# vote_entropy_sampling, consensus_entropy_sampling, max_disagreement_sampling\n",
    "QBC_STRATEGY = max_disagreement_sampling\n",
    "\n",
    "# Set whether to oversample, undersample, or neither. Should NOT have over- and undersampling both be True\n",
    "OVERSAMPLE = False\n",
    "UNDERSAMPLE = False\n",
    "SAMPLING_RATIO = 0.25\n",
    "\n",
    "# Weighing factor, (in favor of the targete class) \n",
    "WEIGHTING_FACTOR = 0.15\n",
    "\n",
    "# Whether to scale data and apply PCA (PCA currently disabled -> commented out)\n",
    "SC_PCA = False\n",
    "\n",
    "# whether to save results from current test as figures\n",
    "SAVEFIGS = False\n",
    "SAVERATIO = False\n",
    "SAVERESULTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for altering settings between runs. Settings that should generally stay consistent between runs are not changed by this method. \n",
    "# This can also be done by the main run_test method, making this method obsolete.\n",
    "def set_settings(k_, execs_, n_queries_, n_init_, train_sum_, sep_class_, ml_method_, ml_sep_method_, al_method_, qbc_learners_, n_qbc_learners_, weighting_factor_, save_figs_, save_ratio_, save_results_, bandwidth_ = 0, sc_pca_ = True):\n",
    "    global K, EXECUTIONS, N_QUERIES, INITIALIZATION_SET, TRAIN_ON_SUM, SEPARATE_CLASSIFIER, ML_METHOD, ML_SEP_METHOD, AL_METHOD, QBC_LEARNERS, N_QBC_LEARNERS, OVERSAMPLE, UNDERSAMPLE, WEIGHTING_FACTOR, SAMPLING_RATIO, SAVEFIGS, SAVERATIO, SAVERESULTS, BANDWIDTH, SC_PCA\n",
    "    K = k_\n",
    "    EXECUTIONS = execs_\n",
    "    N_QUERIES = n_queries_\n",
    "    INITIALIZATION_SET = n_init_\n",
    "    TRAIN_ON_SUM = train_sum_\n",
    "    \n",
    "    SEPARATE_CLASSIFIER = sep_class_\n",
    "    ML_METHOD = ml_method_\n",
    "    ML_SEP_METHOD = ml_sep_method_\n",
    "    \n",
    "    AL_METHOD = al_method_\n",
    "    QBC_LEARNERS = qbc_learners_\n",
    "    N_QBC_LEARNERS = n_qbc_learners_\n",
    "    \n",
    "    # normally calculated if set to 0\n",
    "    BANDWIDTH = bandwidth_\n",
    "    \n",
    "    # Undersampling or oversampling according to the sampling ratio defined in the base settings\n",
    "    UNDERSAMPLE = False\n",
    "    OVERSAMPLE = False\n",
    "\n",
    "    WEIGHTING_FACTOR = weighting_factor_\n",
    "    SC_PCA = sc_pca_\n",
    "    \n",
    "    SAVEFIGS = save_figs_\n",
    "    SAVERATIO = save_ratio_\n",
    "    SAVERESULTS = save_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openml_test(data, k_, execs_, n_queries_, n_init_, train_sum_, sep_class_, ml_method_, ml_sep_method_, al_method_, qbc_learners_, n_qbc_learners_, weighting_factor_, save_figs_, save_ratio_, save_results_, time_point = None, bandwidth_ = 0, pal_priors = 1, sc_pca_ = True):\n",
    "    # Seed to allow different AL methods to train and test with the same splits and initialization sets over the course of the same number of executions with the same settings.\n",
    "    np.random.seed(0)\n",
    "    # Call the set_settings method to change settings as defined by the parameters of this method.\n",
    "    set_settings(k_, execs_, n_queries_, n_init_, train_sum_, sep_class_, ml_method_, ml_sep_method_, al_method_, qbc_learners_, n_qbc_learners_, weighting_factor_, save_figs_, save_ratio_, save_results_, bandwidth_, sc_pca_)\n",
    "    \n",
    "    # Keep track of results for each query. Used later to calculate incremental performance. +1 because the first value is the performance directly after initialization\n",
    "    accuracy_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    macro_f1_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    recall_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    precision_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    auc_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    \n",
    "    # Keep track of feature importance during training. \n",
    "    feat_importance_cons = pd.DataFrame([], columns = range(N_QUERIES + 1), index = range(EXECUTIONS * K))\n",
    "    if SEPARATE_CLASSIFIER:\n",
    "        feat_importance_prod = pd.DataFrame([], columns = range(N_QUERIES + 1), index = range(EXECUTIONS * K))\n",
    "\n",
    "    # Keep track of label ratio in data and selected label ratio\n",
    "    balance_ratios = pd.DataFrame(columns = [\"Training Folds Ratio\", \"Selected Training Instances Ratio\"])\n",
    "    selected_instances_table = pd.DataFrame(columns = range(N_QUERIES))\n",
    "\n",
    "    # Keep track of selection frequencies of individual trajectories\n",
    "    #trajectory_selection_frequencies = pd.DataFrame(0, index=range(N_QUERIES), columns = looping_sum[trajectory])\n",
    "\n",
    "    # Compute weighting factors for when instance weighting is selected.\n",
    "    #non_target_weight = np.unique(compute_sample_weight('balanced', looping_sum[target]), return_counts=True)[0][0] * (2-WEIGHTING_FACTOR)\n",
    "    #target_weight = np.unique(compute_sample_weight('balanced', looping_sum[target]), return_counts=True)[0][1] * WEIGHTING_FACTOR\n",
    "    \n",
    "    # Perform K-fold validation for EXECUTIONS number of times. This gives more total repetitions, and thus a smoother view of learning performance\n",
    "    for execs in range(EXECUTIONS):\n",
    "        df = data\n",
    "\n",
    "        print(\"Starting execution: \", execs+1, \"/\" , EXECUTIONS,  \"- - - - - - - - \")\n",
    "\n",
    "        unique_classes = df[target].unique()\n",
    "        n_labeled_examples = df.shape[0]\n",
    "\n",
    "        if len(unique_classes) > INITIALIZATION_SET:\n",
    "            print(\"INCREASE SIZE OF INITIALIZATION SET TO INCLUDE AT LEAST ONE INSTANCE OF EACH CLASS\")\n",
    "            raise\n",
    "        \n",
    "        # Make random selection for initialization set based on the sampling ratio and initialization set size\n",
    "        n_minority = math.ceil(int(INITIALIZATION_SET * SAMPLING_RATIO))\n",
    "        n_majority = INITIALIZATION_SET - n_minority\n",
    "        \n",
    "        initialization_indices = np.hstack([df[df[target]==NUM_TARGET].sample(n=n_minority, replace=False).index, \\\n",
    "                                                 df[df[target]!=NUM_TARGET].sample(n=n_majority, replace=False).index])\n",
    "        initialization_set = df.iloc[initialization_indices]\n",
    "\n",
    "        # Isolate the non-initialization examples to make up the sampling pool.\n",
    "        df = df.drop(df.index[initialization_indices]).reset_index(drop=True)\n",
    "\n",
    "        # Create separate set of initialization indices if using full trajectories for training\n",
    "        if not TRAIN_ON_SUM:\n",
    "            full_initialization_set = pd.DataFrame(columns = full_df.columns)\n",
    "\n",
    "            for unique_trajectory in initialization_set[trajectory].unique():\n",
    "                # Retrieve all instances with this trajectory id from full data set\n",
    "                full_initialization_set = full_initialization_set.append(full_df[full_df[trajectory] == unique_trajectory])\n",
    "\n",
    "            # Split into X and y\n",
    "            X_initialize = full_initialization_set.drop(target, axis=1).reset_index(drop=True)\n",
    "            y_initialize = full_initialization_set[target].reset_index(drop=True)\n",
    "            del(full_initialization_set)\n",
    "        else:\n",
    "            # Labeled training instances.\n",
    "            X_initialize = initialization_set.drop(target, axis=1).reset_index(drop=True)\n",
    "            y_initialize = initialization_set[target].reset_index(drop=True)\n",
    "            \n",
    "        # labeled training instances.\n",
    "        X_aggr_initialize = initialization_set.drop(target, axis=1).reset_index(drop=True)\n",
    "        y_aggr_initialize = initialization_set[target].reset_index(drop=True)\n",
    "\n",
    "        X_initialize[trajectory] = X_initialize[trajectory].apply(pd.to_numeric)\n",
    "        y_initialize = pd.to_numeric(y_initialize)\n",
    "\n",
    "        # Take stratified folds to make sure each fold contains enough instances of the majority class\n",
    "        skf = StratifiedKFold(n_splits=K, shuffle = True)\n",
    "        \n",
    "        if time_point != None:\n",
    "            pretime_df, ontime_df = time_specific_summarized_set(df, time_point, 30)\n",
    "    \n",
    "            X_aggr = ontime_df.drop(target, axis=1).to_numpy()\n",
    "            y_aggr = ontime_df[target].to_numpy()\n",
    "            train_set_indices = np.array(list(skf.split(X_aggr, y_aggr)))\n",
    "            \n",
    "        else:\n",
    "            # Split aggregated instances into X and y\n",
    "            X_aggr = df.drop(target, axis=1).to_numpy()\n",
    "            y_aggr = df[target].to_numpy()\n",
    "            train_set_indices = np.array(list(skf.split(X_aggr, y_aggr)))\n",
    "\n",
    "        # K-fold cross validation\n",
    "        for i in range(K):\n",
    "            print(\"Validating on fold: \", i+1 , \"/\", K, end=\"\\r\")\n",
    "            # Set train and test set for current fold\n",
    "            if time_point != None:\n",
    "                X_train = np.vstack([X_aggr[train_set_indices[i][0]], pretime_df.drop(target, axis=1).to_numpy()])\n",
    "                y_train = np.hstack([y_aggr[train_set_indices[i][0]], pretime_df[target].to_numpy()])\n",
    "        \n",
    "                X_test = X_aggr[train_set_indices[i][1]]\n",
    "                y_test = y_aggr[train_set_indices[i][1]]\n",
    "        \n",
    "            else: \n",
    "                X_train = X_aggr[train_set_indices[i][0]]\n",
    "                y_train = y_aggr[train_set_indices[i][0]]\n",
    "                \n",
    "                X_test = X_aggr[train_set_indices[i][1]]\n",
    "                y_test = y_aggr[train_set_indices[i][1]]\n",
    "            \n",
    "            # If the training set has fewer instances than the selected query budget, we have too few instances\n",
    "            if len(X_train) < N_QUERIES:\n",
    "                print(\"TOO FEW TRAINING INSTANCES TO TRAIN THIS FAR. REDUCE TO \", len(X_train))\n",
    "                raise\n",
    "            \n",
    "            # This is why the trajectory identifier needs to be the first column. For creating the folds the dataframe needs to be turned into a numpy array,\n",
    "            # but because of this the ability to select based on name is lost when we try to find these identifiers later.\n",
    "            unique_train_trajectories = np.unique(X_train[:,0])\n",
    "            unique_test_trajectories = np.unique(X_test[:,0])\n",
    "            unique_initialization_trajectories = X_initialize[trajectory].unique()\n",
    "            \n",
    "            fold_full_df = full_df[full_df[trajectory].isin(np.concatenate([unique_initialization_trajectories, unique_train_trajectories, unique_test_trajectories]))]\n",
    "            \n",
    "            # Line only needed when testing without PCA and scaling, but doesn't do harm when not using PCA or scaling\n",
    "            fold_X_initialize = X_initialize\n",
    "\n",
    "            # Currently PCA commented out due to performance decrease for testing during the project. Can be uncommented to inlude PCA again\n",
    "            if SC_PCA:\n",
    "                # Initialization of SC and PCA:\n",
    "                sc = StandardScaler()\n",
    "                pca = PCA(n_components=0.9)\n",
    "\n",
    "                # If training with all trajectory instance, need to scale and fit for this separately from the summarized dataset\n",
    "                if not TRAIN_ON_SUM:\n",
    "                    sc.fit(fold_full_df[fold_full_df[trajectory].isin(unique_train_trajectories)].drop(trajectory,axis=1).drop(target,axis=1))\n",
    "                    fold_full_df = fold_full_df[[trajectory, target]].join(pd.DataFrame(sc.transform(fold_full_df.drop(trajectory,axis=1).drop(target,axis=1)), \\\n",
    "                                                                                            columns=fold_full_df.columns[2:], index=fold_full_df.index))\n",
    "#                     pca.fit(fold_full_df[fold_full_df[trajectory].isin(unique_train_trajectories)].drop(trajectory,axis=1).drop(target,axis=1))\n",
    "#                     fold_full_df = fold_full_df[[trajectory, target]].join(pd.DataFrame(pca.transform(fold_full_df.drop(trajectory,axis=1).drop(target,axis=1)), \\\n",
    "#                                                                                             columns=['PCA%i' %  i for i in range(len(pca.components_))], index=fold_full_df.index))\n",
    "\n",
    "                    # if not using a separte classifier, need to apply same scaling and PCA of full dataset to the summarized one so training and predictions sets don't have different features\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        X_train[:,1:] = sc.transform(X_train[:,1:])\n",
    "                        X_test[:,1:] = sc.transform(X_test[:,1:])\n",
    "                        X_initialize_values = X_initialize.drop(trajectory,axis=1)\n",
    "                        X_initialize_values = pd.DataFrame(sc.transform(X_initialize_values), columns=X_initialize_values.columns, index=X_initialize_values.index)\n",
    "                        fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "\n",
    "#                         X_train = np.hstack((X_train[:,0,np.newaxis], pca.transform(X_train[:,1:])))\n",
    "#                         X_test = np.hstack((X_test[:,0,np.newaxis], pca.transform(X_test[:,1:])))\n",
    "#                         X_initialize_values = fold_X_initialize.drop(trajectory,axis=1)\n",
    "#                         X_initialize_values = pd.DataFrame(pca.transform(X_initialize_values), columns=['PCA%i' %  i for i in range(len(pca.components_))], index=X_initialize_values.index)\n",
    "#                         fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "                    else:\n",
    "                        X_train[:,1:] = sc.fit_transform(X_train[:,1:])\n",
    "                        X_test[:,1:] = sc.transform(X_test[:,1:])\n",
    "                        X_initialize_values = X_initialize.drop(trajectory,axis=1)\n",
    "                        X_initialize_values = pd.DataFrame(sc.transform(X_initialize_values), columns=X_initialize_values.columns, index=X_initialize_values.index)\n",
    "                        fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "\n",
    "#                         X_train = np.hstack((X_train[:,0,np.newaxis], pca.fit_transform(X_train[:,1:])))\n",
    "#                         X_test = np.hstack((X_test[:,0,np.newaxis], pca.transform(X_test[:,1:])))\n",
    "#                         X_initialize_values = fold_X_initialize.drop(trajectory,axis=1)\n",
    "#                         X_initialize_values = pd.DataFrame(pca.transform(X_initialize_values), columns=['PCA%i' %  i for i in range(len(pca.components_))], index=X_initialize_values.index)\n",
    "#                         fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "                else:\n",
    "                    X_train[:,1:] = sc.fit_transform(X_train[:,1:])\n",
    "                    X_test[:,1:] = sc.transform(X_test[:,1:])\n",
    "                    X_initialize_values = X_initialize.drop(trajectory,axis=1)\n",
    "                    X_initialize_values = pd.DataFrame(sc.transform(X_initialize_values), columns=X_initialize_values.columns, index=X_initialize_values.index)\n",
    "                    fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "\n",
    "#                     X_train = np.hstack((X_train[:,0,np.newaxis], pca.fit_transform(X_train[:,1:])))\n",
    "#                     X_test = np.hstack((X_test[:,0,np.newaxis], pca.transform(X_test[:,1:])))\n",
    "#                     X_initialize_values = fold_X_initialize.drop(trajectory,axis=1)\n",
    "#                     X_initialize_values = pd.DataFrame(pca.transform(X_initialize_values), columns=['PCA%i' %  i for i in range(len(pca.components_))], index=X_initialize_values.index)\n",
    "#                     fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "            \n",
    "            # Backup that allows for multiple ways of using the same y_test name but handling performance measures in different ways\n",
    "            y_test_original = y_test\n",
    "\n",
    "            if OVERSAMPLE and UNDERSAMPLE:\n",
    "                print(\"CAN'T UNDER AND OVERSAMPLE AT THE SAME TIME\")\n",
    "                raise\n",
    "            if OVERSAMPLE:\n",
    "                sampler = RandomOverSampler(sampling_strategy=SAMPLING_RATIO)\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "            elif UNDERSAMPLE:\n",
    "                sampler = RandomUnderSampler(sampling_strategy=SAMPLING_RATIO)\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Save class ratio of instances in training fold\n",
    "            fold_training_ratio = np.count_nonzero(y_train == NUM_TARGET)/np.count_nonzero(y_train != NUM_TARGET) # MOSTLY MAKES SENSE FOR BINARY TARGET CLASS\n",
    "\n",
    "            model = ML_switcher.get(ML_METHOD)\n",
    "\n",
    "            if AL_METHOD == 5 and not SEPARATE_CLASSIFIER: # Using QBC for main classifier, NOT RECOMMENDED WHEN COMPARING AL METHODS\n",
    "                committee_list = []\n",
    "                unique_trajectories_init = fold_X_initialize[trajectory].unique()\n",
    "                qbc_initialization_size = math.ceil(INITIALIZATION_SET/(N_QBC_LEARNERS*len(QBC_LEARNERS))) + 1\n",
    "                \n",
    "                # For each specified QBC member, create N_QBC_LEARNERS learners to be added to the committee\n",
    "                for qbc_model in QBC_LEARNERS:\n",
    "                    # select random numbers, find trip id's for these in the aggr dataset. Then select all instances with these id's from the initilizing set and use them as new initializing set\n",
    "                    for n in range(N_QBC_LEARNERS):\n",
    "                        original_estimator = ML_switcher.get(qbc_model)\n",
    "                        new_estimator = deepcopy(original_estimator)\n",
    "                        \n",
    "                        # The number of items for initializing the committe members is the proportion of number of members to size of the initialization set, rounded up.\n",
    "                        # Considering the initialization set is usually small in this case due to low amounts of data, replacement is allowed which results insome overlap \n",
    "                        # in intialization sets make random selection for initialization set based on the sampling ratio and initialization set size\n",
    "                        n_minority = math.ceil(int(qbc_initialization_size * SAMPLING_RATIO)) + 1\n",
    "                        n_majority = qbc_initialization_size - n_minority\n",
    "\n",
    "                        unique_negative_target = np.random.choice(initialization_set[initialization_set[target] != NUM_TARGET][trajectory].unique(),n_majority,replace=True)\n",
    "                        unique_positive_target = np.random.choice(initialization_set[initialization_set[target] == NUM_TARGET][trajectory].unique(),n_minority,replace=True)\n",
    "                        trajectories_init = np.concatenate((unique_positive_target, unique_negative_target), axis=None)\n",
    "                        \n",
    "                        idx_member_init = fold_X_initialize.index[fold_X_initialize[trajectory].isin(trajectories_init)].to_numpy()\n",
    "\n",
    "                        X_member_init = fold_X_initialize.iloc[idx_member_init].to_numpy()\n",
    "                        y_member_init = y_initialize.iloc[idx_member_init].to_numpy()\n",
    "\n",
    "                        # Initializing learner\n",
    "                        committee_member =  ActiveLearner(\n",
    "                            estimator=new_estimator,\n",
    "                            X_training=X_member_init, y_training=y_member_init\n",
    "                        )\n",
    "                        committee_list.append(committee_member)\n",
    "\n",
    "                # Assembling the committee\n",
    "                learner = Committee(\n",
    "                    learner_list=committee_list,\n",
    "                    query_strategy=QBC_STRATEGY\n",
    "                )\n",
    "            else: # NOT using QBC for main classifier. Should pretty much be always the case\n",
    "                # Specify the core estimator along with its active learning model. Fit with the labeled data set\n",
    "                learner = ActiveLearner(\n",
    "                    estimator=deepcopy(model),\n",
    "                    query_strategy=AL_switcher.get(AL_METHOD),\n",
    "                    X_training=fold_X_initialize.to_numpy(), y_training=y_initialize.to_numpy()\n",
    "                )\n",
    "\n",
    "            # Create separate classifer for training and estimation\n",
    "            if SEPARATE_CLASSIFIER:\n",
    "                query_model = deepcopy(ML_switcher.get(ML_SEP_METHOD))\n",
    "                new_query_strategy = deepcopy(AL_switcher.get(AL_METHOD))\n",
    "\n",
    "                if AL_METHOD != 5:\n",
    "                    query_estimator = ActiveLearner(\n",
    "                            estimator=query_model,\n",
    "                            query_strategy=new_query_strategy,\n",
    "                            X_training=X_aggr_initialize.to_numpy(), y_training=y_aggr_initialize.to_numpy()\n",
    "                    )\n",
    "                else:\n",
    "                    committee_list = []\n",
    "                    unique_trajectories_init = X_aggr_initialize[trajectory].unique()\n",
    "                    qbc_initialization_size = math.ceil(INITIALIZATION_SET/(N_QBC_LEARNERS*len(QBC_LEARNERS)))+1\n",
    "                    \n",
    "                    # For each specified QBC member, create N_QBC_LEARNERS learners to be added to the committee\n",
    "                    for qbc_model in QBC_LEARNERS:\n",
    "                        \n",
    "                        # select random numbers, find trip id's for these in the aggr dataset. Then select all instances with these id's from the initilizing set and use them as new initializing set\n",
    "                        for n in range(N_QBC_LEARNERS):\n",
    "                            original_estimator = deepcopy(ML_switcher.get(qbc_model))\n",
    "                            new_estimator = deepcopy(original_estimator)\n",
    "                            \n",
    "                            # make random selection for initialization set based on the sampling ratio and initialization set size\n",
    "                            n_minority = math.ceil(int(qbc_initialization_size * SAMPLING_RATIO)) + 1\n",
    "                            n_majority = qbc_initialization_size - n_minority\n",
    "\n",
    "                            unique_negative_target = np.random.choice(initialization_set[initialization_set[target] != NUM_TARGET][trajectory].unique(),n_majority,replace=False)\n",
    "                            unique_positive_target = np.random.choice(initialization_set[initialization_set[target] == NUM_TARGET][trajectory].unique(),n_minority,replace=False)\n",
    "                            \n",
    "                            trajectories_init = np.hstack([unique_positive_target, unique_negative_target])\n",
    "\n",
    "                            idx_member_init = X_aggr_initialize[X_aggr_initialize[trajectory].isin(trajectories_init)].index.to_numpy()\n",
    "\n",
    "                            X_member_init = X_aggr_initialize.iloc[idx_member_init].to_numpy()\n",
    "                            y_member_init = y_aggr_initialize.iloc[idx_member_init].to_numpy()\n",
    "\n",
    "                            # initializing learner\n",
    "                            committee_member =  ActiveLearner(\n",
    "                                estimator=new_estimator,\n",
    "                                X_training=X_member_init, y_training=y_member_init\n",
    "                            )\n",
    "                            committee_list.append(committee_member)\n",
    "\n",
    "                    # Assembling the committee\n",
    "                    query_estimator = Committee(\n",
    "                        learner_list=committee_list,\n",
    "                        query_strategy=vote_entropy_sampling\n",
    "                    )\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "            # Make first set of predictions (before querying)\n",
    "            predictions = []\n",
    "\n",
    "            if TRAIN_ON_SUM:\n",
    "                predictions = learner.predict(X_test)\n",
    "\n",
    "            else:\n",
    "                # Training with all instances performance 1: Evaluating performance only for the summarizing instance (in this case single point at end of trajectory)\n",
    "                predictions_single = learner.predict(X_test)\n",
    "\n",
    "                unqueried_score_single = accuracy_score(y_test, predictions_single)\n",
    "                unqueried_macro_f1_single = f1_score(y_test, predictions_single, average='macro')\n",
    "                unqueried_recall_single = recall_score(y_test, predictions_single, average='macro')\n",
    "                unqueried_precision_single = precision_score(y_test, predictions_single, average='macro', zero_division=0)\n",
    "                unqueried_auc_single = roc_auc_score(y_test, predictions_single, average = 'macro')\n",
    "\n",
    "                # Store performance of every calculated score\n",
    "                accuracy_history_single = [unqueried_score_single]\n",
    "                macro_f1_history_single = [unqueried_macro_f1_single]\n",
    "                recall_history_single = [unqueried_recall_single]\n",
    "                precision_history_single = [unqueried_precision_single]\n",
    "                auc_history_single = [unqueried_auc_single]\n",
    "\n",
    "                # Training with all instances performance 2: Evaluate performance by classifying all individual instances of each trajectory and taking a majority vote to get a \n",
    "                # prediction for that one trajectory.\n",
    "                y_test = []\n",
    "                for unique_trajectory in unique_test_trajectories:\n",
    "                    # Retrieve all instances with this trajectory id from full data set\n",
    "                    test_trajectory_full = fold_full_df[fold_full_df[trajectory] == unique_trajectory]\n",
    "                    # Split into numpy X and y\n",
    "                    X_test_full = test_trajectory_full.drop(target, axis=1).to_numpy()\n",
    "\n",
    "                    y_test.append(test_trajectory_full[target].to_numpy()[0])\n",
    "                    del(test_trajectory_full)\n",
    "\n",
    "                    # get prediction of one trajectory via majority vote of all its inividual instance classifications\n",
    "                    trajectory_prediction = np.bincount(learner.predict(X_test_full).astype(int)).argmax() # not sure why this has to be cast as int, already should be\n",
    "\n",
    "                    # append prediction to a list\n",
    "                    predictions.append(trajectory_prediction)\n",
    "                del(X_test_full)\n",
    "\n",
    "            # Record our learner's performance on the test data\n",
    "            unqueried_score = accuracy_score(y_test, predictions)\n",
    "            unqueried_macro_f1 = f1_score(y_test, predictions, average='macro')\n",
    "            unqueried_recall = recall_score(y_test, predictions, average='macro')\n",
    "            unqueried_precision = precision_score(y_test, predictions, average='macro', zero_division=0)\n",
    "            unqueried_auc = roc_auc_score(y_test, predictions, average = 'macro')\n",
    "\n",
    "            # Store performance of every calculated score\n",
    "            accuracy_history = [unqueried_score]\n",
    "            macro_f1_history = [unqueried_macro_f1]\n",
    "            recall_history = [unqueried_recall]\n",
    "            precision_history = [unqueried_precision]\n",
    "            auc_history = [unqueried_auc]\n",
    "\n",
    "            # Store feature importance.  For QBC, average importances of all committe members taken (although the differences between the members could be interesting)\n",
    "            if AL_METHOD != 5:\n",
    "                if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                    feat_importance_cons.iat[0,0] = abs(learner.estimator.coef_)[0]\n",
    "                else:\n",
    "                    feat_importance_cons.iat[0,0] = learner.estimator.feature_importances_\n",
    "                if SEPARATE_CLASSIFIER:\n",
    "                    if query_estimator.estimator.__class__.__name__ == \"SVC\" or query_estimator.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                        feat_importance_prod.iat[0,0] = abs(query_estimator.estimator.coef_)[0]\n",
    "                    else:\n",
    "                        feat_importance_prod.iat[0,0] = query_estimator.estimator.feature_importances_\n",
    "            else:\n",
    "                if not SEPARATE_CLASSIFIER:    \n",
    "                    feat_importance_cons.iat[0,0] = 0\n",
    "                    for member in learner:\n",
    "                        if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                            feat_importance_cons.iat[0,0] += abs(member.estimator.coef_)[0]\n",
    "                        else:\n",
    "                            feat_importance_cons.iat[0,0] += member.estimator.feature_importances_\n",
    "                        feat_importance_cons.iat[0,0] = feat_importance_cons.iat[0,0] / len(learner)\n",
    "                else:\n",
    "                    if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                        feat_importance_cons.iat[0,0] = abs(learner.estimator.coef_)[0]\n",
    "                    else:\n",
    "                        feat_importance_cons.iat[0,0] = learner.estimator.feature_importances_\n",
    "\n",
    "                    feat_importance_prod.iat[0,0] = 0\n",
    "                    for member in query_estimator:\n",
    "                        if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                            feat_importance_prod.iat[0,0] += abs(member.estimator.coef_)[0]\n",
    "                        else:\n",
    "                            feat_importance_prod.iat[0,0] += member.estimator.feature_importances_\n",
    "                        feat_importance_prod.iat[0,0] = feat_importance_prod.iat[0,0] / len(query_estimator)\n",
    "            \n",
    "            # Labels of selected training instances. Used for calculating metrics later on\n",
    "            selected_training_instance_labels = np.array([])\n",
    "            \n",
    "            \n",
    "            # For PAL: calculating gamma through bandwidth, with mean as default and using rbf as the kernel\n",
    "            nominator = 2 * len(X_test) * len(X_test[0]) # number of instances, number of features\n",
    "            denominator = (len(X_test) - 1) * np.log((len(X_test) - 1) / ((np.sqrt(2) * 10 ** -6) ** 2))\n",
    "            bandwidth = np.sqrt(nominator / denominator)\n",
    "            \n",
    "            if BANDWIDTH == 0:\n",
    "                bandwidth = np.sqrt(nominator / denominator)\n",
    "            else: bandwidth = BANDWIDTH\n",
    "            \n",
    "            gamma = 0.5 * (bandwidth ** (-2))\n",
    "            \n",
    "            # Perform training and testing for the budget of N_QUERIES. The \"unlabeled\" dataset is queried for the most informative points according to our query strategy\n",
    "            # which are consecutively added to the training set after which performance is directly measured.\n",
    "            for index in range(N_QUERIES):\n",
    "                # Setting up kernel with rbf as default and additional parameters (for PAL and xPAL)\n",
    "                params = {}\n",
    "                if AL_METHOD == 6 or AL_METHOD == 7 or AL_METHOD == 8 or AL_METHOD == 9:\n",
    "                    S =  pairwise_kernels(X = X_train, Y = X_train, metric='rbf', gamma=gamma)\n",
    "                    S = check_array(S, np.eye(len(X_train)))\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        params = {'n_classes': len(unique_classes), \"labeled_instances\": query_estimator.X_training, \"labels\": query_estimator.y_training, \"kernel\": S, \"priors\": pal_priors}\n",
    "                    else: \n",
    "                        params = {'n_classes': len(unique_classes), \"labeled_instances\": learner.X_training, \"labels\": learner.y_training, \"kernel\": S, \"priors\": pal_priors}\n",
    "\n",
    "                # Query instance using AL method\n",
    "                if SEPARATE_CLASSIFIER:\n",
    "                    query_index, query_instance = query_estimator.query(X_train, **params)\n",
    "                else:\n",
    "                    query_index, query_instance = learner.query(X_train, **params)\n",
    "\n",
    "                # For measuring frequencies of selection of specific trajectories over the course of learning\n",
    "                trajectory_selection_frequencies.iloc[index][int(X_train[query_index,0])] += 1\n",
    "                \n",
    "                # For measuring performance in terms of label selection\n",
    "                selected_training_instance_labels = np.append(selected_training_instance_labels, y_train[query_index])\n",
    "\n",
    "                # logic to make sure only do additional bootstrapping when using qbc, and only on the QBC classifiers\n",
    "                boot_main = False\n",
    "                boot_sep = False\n",
    "#                 # This currently breaks. The bootstrapping takes random samples, but there are too few in the initialization set to guarantee at least one of each class\n",
    "#                 if AL_METHOD == 5:\n",
    "#                     if SEPARATE_CLASSIFIER:\n",
    "#                         boot_main = False\n",
    "#                         boot_sep = True\n",
    "#                     else:\n",
    "#                         boot_main = True\n",
    "#                         boot_sep = True\n",
    "                \n",
    "                # Setting weighting of training instances when not randomly selecting them. Using two arrays guarantees that no overlapping values erase each other\n",
    "                #if WEIGHTING_FACTOR != 0 and AL_METHOD != 1 and AL_METHOD != 5:\n",
    "                #    current_labels = np.append(learner.y_training, y_train[query_index].reshape(1, ))\n",
    "                #    sample_weights = np.zeros(len(current_labels)).astype(float)\n",
    "                #    temp_indices = np.where(current_labels == NUM_TARGET)\n",
    "                #    sample_weights[temp_indices] = target_weight\n",
    "                #    temp_indices = np.where(current_labels != NUM_TARGET)\n",
    "                #    sample_weights[temp_indices] = non_target_weight\n",
    "                #else:\n",
    "                #    sample_weights = None\n",
    "    \n",
    "        \n",
    "                # Training the consumer with the summarizing queried instance\n",
    "                if TRAIN_ON_SUM:\n",
    "                    # Train our ActiveLearner model with the instance it has requested.\n",
    "                    X_temp, y_temp = X_train[query_index].reshape(1, -1), y_train[query_index].reshape(1, )\n",
    "                    learner.teach(X=X_temp, y=y_temp, bootstrap=boot_main, sample_weight = sample_weights)\n",
    "\n",
    "                    # Training a separate classifier (producer) with the summarizing queried instance\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        X_temp, y_temp = X_train[query_index].reshape(1, -1), y_train[query_index].reshape(1, )\n",
    "                        query_estimator.teach(X=X_temp, y=y_temp, bootstrap=boot_sep, sample_weight = sample_weights)\n",
    "\n",
    "                # Training the model with all instances of queried trip\n",
    "                else:\n",
    "                    # Training a separate classifier (producer) used for selecting queries\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        X_temp, y_temp = X_train[query_index].reshape(1, -1), y_train[query_index].reshape(1, )\n",
    "                        \n",
    "                        #if WEIGHTING_FACTOR != 0 and AL_METHOD != 1 and AL_METHOD != 5:\n",
    "                        #    current_labels = np.append(query_estimator.y_training, y_train[query_index].reshape(1, ))\n",
    "                        #    sample_weights = np.zeros(len(current_labels)).astype(float)\n",
    "                        #    temp_indices = np.where(current_labels == NUM_TARGET)\n",
    "                        #    sample_weights[temp_indices] = target_weight\n",
    "                        #    temp_indices = np.where(current_labels != NUM_TARGET)\n",
    "                        #    sample_weights[temp_indices] = non_target_weight\n",
    "                        #else:\n",
    "                        #    sample_weights = None\n",
    "                        \n",
    "                        query_estimator.teach(X=X_temp, y=y_temp, bootstrap = boot_sep, sample_weight = sample_weights)\n",
    "\n",
    "                    # Find trip_id of selected query in aggregated instances\n",
    "                    query_trajectory_id = X_train[query_index,0]\n",
    "                    # Retrieve all instances with this trajectory id from full data set\n",
    "\n",
    "                    if not isinstance(query_trajectory_id, float):\n",
    "                        query_trajectory_id = query_trajectory_id[0]\n",
    "                    query_trajectory_full = fold_full_df[fold_full_df[trajectory] == query_trajectory_id] # for sep classifier the specific formatting returns one element in two dimensions\n",
    "\n",
    "                    # Split into numpy X and y\n",
    "                    X_train_full = query_trajectory_full.drop(target, axis=1).to_numpy()\n",
    "                    y_train_full = query_trajectory_full[target].to_numpy()\n",
    "                    del(query_trajectory_full)\n",
    "\n",
    "                    #if WEIGHTING_FACTOR != 0 and AL_METHOD != 1 and AL_METHOD != 5:\n",
    "                    #    current_labels = np.append(learner.y_training, y_train_full)\n",
    "                    #    sample_weights = np.zeros(len(current_labels)).astype(float)\n",
    "                    #    temp_indices = np.where(current_labels == NUM_TARGET)\n",
    "                    #    sample_weights[temp_indices] = target_weight\n",
    "                    #    temp_indices = np.where(current_labels != NUM_TARGET)\n",
    "                    #    sample_weights[temp_indices] = 1 - (non_target_weight * 0.1)\n",
    "                    #else:\n",
    "                    #    sample_weights = None\n",
    "                    \n",
    "                    # Add selected instances to training pool and teach the model re-train the model on the new set\n",
    "                    # Train the consumer on either the full or \n",
    "                    learner.teach(X=X_train_full, y=y_train_full, bootstrap=boot_main, sample_weight = sample_weights)\n",
    "\n",
    "                    del(X_train_full)\n",
    "                    del(y_train_full)\n",
    "\n",
    "                # Remove the queried instance from the unlabeled pool.\n",
    "                X_train, y_train = np.delete(X_train, query_index, axis=0), np.delete(y_train, query_index)\n",
    "\n",
    "                predictions = []\n",
    "                # Evluate performance of\n",
    "                if TRAIN_ON_SUM:\n",
    "                    # Make predictions\n",
    "                    predictions = learner.predict(X_test)\n",
    "\n",
    "                # Evaluate performance on full trajectories by classifying all individual instances of each trajectory and taking a majority vote to get a prediction for that one trajectory\n",
    "                else:\n",
    "                    predictions_single = learner.predict(X_test)\n",
    "\n",
    "                    # Calculate and report our model's accuracy for last instance.\n",
    "                    model_accuracy_single = accuracy_score(y_test_original, predictions_single)\n",
    "                    model_macro_f1_single = f1_score(y_test_original, predictions_single, average='macro')\n",
    "                    model_recall_single = recall_score(y_test_original, predictions_single, average='macro')\n",
    "                    model_precision_single = precision_score(y_test_original, predictions_single, average='macro', zero_division=0) # zero_division because sometimes no preictions of looping class\n",
    "                    model_auc_single = roc_auc_score(y_test_original, predictions_single, average = 'macro')\n",
    "                    \n",
    "                    accuracy_history_single.append(model_accuracy_single)\n",
    "                    macro_f1_history_single.append(model_macro_f1_single)\n",
    "                    recall_history_single.append(model_recall_single)\n",
    "                    precision_history_single.append(model_precision_single)  \n",
    "                    auc_history_single.append(model_auc_single)\n",
    "                    \n",
    "                    y_test = []\n",
    "                    for unique_trajectory in unique_test_trajectories:\n",
    "                        # Retrieve all instances with this trajectory id from full data set\n",
    "                        test_trajectory_full = fold_full_df[fold_full_df[trajectory] == unique_trajectory]\n",
    "\n",
    "                        # Split into numpy X and y\n",
    "                        X_test_full = test_trajectory_full.drop(target, axis=1).to_numpy()\n",
    "                        y_test.append(test_trajectory_full[target].to_numpy()[0])\n",
    "                        del(test_trajectory_full)\n",
    "\n",
    "                        # Get prediction of one trajectory via majority vote of all its inividual instance classifications\n",
    "                        trajectory_prediction = np.bincount(learner.predict(X_test_full).astype(int)).argmax()\n",
    "                        # append prediction to a list\n",
    "                        predictions.append(trajectory_prediction)\n",
    "\n",
    "                # Calculate and report our model's accuracy.\n",
    "                model_accuracy = accuracy_score(y_test, predictions)\n",
    "                model_macro_f1 = f1_score(y_test, predictions, average='macro')\n",
    "                model_recall = recall_score(y_test, predictions, average='macro')\n",
    "                model_precision = precision_score(y_test, predictions, average='macro', zero_division=0) # zero_division because sometimes no preictions of looping class\n",
    "                model_auc = roc_auc_score(y_test, predictions, average = 'macro')\n",
    "\n",
    "                # Save our model's performance for plotting.\n",
    "                accuracy_history.append(model_accuracy)\n",
    "                macro_f1_history.append(model_macro_f1)\n",
    "                recall_history.append(model_recall)\n",
    "                precision_history.append(model_precision)\n",
    "                auc_history.append(model_auc)\n",
    "                \n",
    "                # Store feature importance.  For the time being, taking average feature importance of QBC members, although the differences between the members should be interesting\n",
    "                if AL_METHOD != 5:\n",
    "                    if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                        feat_importance_cons.iat[execs * K + i, index+1] = abs(learner.estimator.coef_)[0]\n",
    "                    else:\n",
    "                        feat_importance_cons.iat[execs * K + i, index+1] = learner.estimator.feature_importances_\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                            if query_estimator.estimator.__class__.__name__ == \"SVC\" or query_estimator.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] = abs(query_estimator.estimator.coef_)[0]\n",
    "                            else:\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] = query_estimator.estimator.feature_importances_\n",
    "                else:\n",
    "                    if not SEPARATE_CLASSIFIER:\n",
    "                        feat_importance_cons.iat[execs * K + i, index+1] = 0\n",
    "                        for member in learner:\n",
    "                            if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                                feat_importance_cons.iat[execs * K + i, index+1] += abs(member.estimator.coef_)[0]\n",
    "                            else:\n",
    "                                feat_importance_cons.iat[execs * K + i, index+1] += member.estimator.feature_importances_\n",
    "                            feat_importance_cons.iat[execs * K + i, index+1] = feat_importance_cons.iat[execs * K + i, index+1] / len(learner)\n",
    "                    else:\n",
    "                        if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                            feat_importance_cons.iat[execs * K + i, index+1] = abs(learner.estimator.coef_)[0]\n",
    "                        else:\n",
    "                            feat_importance_cons.iat[execs * K + i, index+1] = learner.estimator.feature_importances_\n",
    "                        \n",
    "                        feat_importance_prod.iat[execs * K + i, index+1] = 0\n",
    "                        for member in query_estimator:\n",
    "                            if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] += abs(member.estimator.coef_)[0]\n",
    "                            else:\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] += member.estimator.feature_importances_\n",
    "                            feat_importance_prod.iat[execs * K + i, index+1] = feat_importance_prod.iat[execs * K + i, index+1] / len(query_estimator)\n",
    "                \n",
    "            # Save the class ratio over the cross validation\n",
    "            selected_training_ratio = np.count_nonzero(selected_training_instance_labels == NUM_TARGET)/ (len(selected_training_instance_labels) - np.count_nonzero(selected_training_instance_labels == NUM_TARGET))\n",
    "            series_ratios = pd.Series([fold_training_ratio, selected_training_ratio], index = balance_ratios.columns)\n",
    "            balance_ratios = balance_ratios.append(series_ratios, ignore_index=True)\n",
    "\n",
    "            # Save the specific labels chosen at each training point\n",
    "            selected_instances_table = selected_instances_table.append(pd.Series(selected_training_instance_labels), ignore_index=True)\n",
    "\n",
    "            # store results after each test\n",
    "            accuracy_results = accuracy_results.append(pd.Series(accuracy_history), ignore_index=True)\n",
    "            macro_f1_results = macro_f1_results.append(pd.Series(macro_f1_history), ignore_index=True)\n",
    "            recall_results = recall_results.append(pd.Series(recall_history), ignore_index=True)\n",
    "            precision_results = precision_results.append(pd.Series(precision_history), ignore_index=True)\n",
    "            auc_results = auc_results.append(pd.Series(auc_history), ignore_index = True)\n",
    "\n",
    "            if not TRAIN_ON_SUM:\n",
    "                accuracy_results_single = accuracy_results_single.append(pd.Series(accuracy_history_single), ignore_index=True)\n",
    "                macro_f1_results_single = macro_f1_results_single.append(pd.Series(macro_f1_history_single), ignore_index=True)\n",
    "                recall_results_single = recall_results_single.append(pd.Series(recall_history_single), ignore_index=True)\n",
    "                precision_results_single = precision_results_single.append(pd.Series(precision_history_single), ignore_index=True)\n",
    "                auc_results_single = auc_results.append(pd.Series(auc_history_single), ignore_index = True)\n",
    "            \n",
    "    # Modify selected instances table so that only the positive class is a 1, the rest is 0. This makes the average value the selected class ratio\n",
    "    # This is a problem if the target class is 0, because then all values will be set to 1.\n",
    "    # Quick workaround of first setting all non-target values to 2, then setting these to 0 after setting the target values to 1. \n",
    "    # LIKELY BREAKS WHEN NO BINARY TARGET CLASS\n",
    "    if NUM_TARGET != 0:\n",
    "        selected_instances_table[selected_instances_table != NUM_TARGET] = 0\n",
    "        selected_instances_table[selected_instances_table == NUM_TARGET] = 1\n",
    "    else:\n",
    "        selected_instances_table[selected_instances_table != NUM_TARGET] = 2\n",
    "        selected_instances_table[selected_instances_table == NUM_TARGET] = 1\n",
    "        selected_instances_table[selected_instances_table == 2] = 0\n",
    "        \n",
    "    all_results = list([macro_f1_results, recall_results, precision_results, selected_instances_table, auc_results])\n",
    "    if not TRAIN_ON_SUM:\n",
    "        all_results_single = list([macro_f1_results_single, recall_results_single, precision_results_single, selected_instances_table, auc_results_single])\n",
    "    \n",
    "    print(\"******************* FINISHED *******************\")\n",
    "    print(\"\\n\")\n",
    "    print(balance_ratios.describe())\n",
    "    \n",
    "    # Set variables used for naming the results files\n",
    "    if TRAIN_ON_SUM:\n",
    "        train = \"sum_\"\n",
    "    else: train = \"full_\"\n",
    "    if SEPARATE_CLASSIFIER:\n",
    "        sep_class = \"sep_\"\n",
    "    else: sep_class = \"same_\"\n",
    "    if OVERSAMPLE and UNDERSAMPLE:\n",
    "        print(\"CAN'T OVER AND UNDERSAMPLE AT THE SAME TIME\")\n",
    "        raise()\n",
    "    if OVERSAMPLE:\n",
    "        samp_ratio = \"OVER_\" + str(SAMPLING_RATIO)\n",
    "    elif UNDERSAMPLE:\n",
    "        samp_ratio = \"UNDER_\" + str(SAMPLING_RATIO)\n",
    "    else: samp_ratio = \"\"\n",
    "    if AL_METHOD == 5:\n",
    "        learners_qbc = '+'.join(str(x) for x in QBC_LEARNERS) + \"_\" + str(N_QBC_LEARNERS) + \"_\"\n",
    "    else: learners_qbc = \"\"\n",
    "    if AL_METHOD == 6 or AL_METHOD == 7:\n",
    "        bdwidth = \"BD_\" + str(BANDWIDTH)\n",
    "    else: bdwidth = \"\"\n",
    "    if AL_METHOD == 1:\n",
    "        weight = ''\n",
    "    else: weight = \"WF\" + str(WEIGHTING_FACTOR) + \"_\"\n",
    "    if OLD_DATA:\n",
    "        old = \"OLD_\"\n",
    "    else: old = \"\"\n",
    "    if time_point == None:\n",
    "        time_point_test = \"\"\n",
    "    elif time_point == 'all': \n",
    "        time_point_test = 'all_time_points_'\n",
    "    else: time_point_test = str(time_point) + \"_\"\n",
    "        \n",
    "    string = AL_switcher.get(AL_METHOD).__name__ + \"_\" + weight + old + bdwidth + learners_qbc + sep_class + train + \"maj_\" + samp_ratio + str(N_QUERIES) + \"_\" + time_point_test + \"_new\"\n",
    "    measure_names = ['F1', 'Recall', 'Precision', \"Selected Label Ratio\", \"AUC\", \"Feature Importance Consumer\", \"Feature Importance Producer\"]\n",
    "    measure_names = measure_names [:len(all_results)]\n",
    "    \n",
    "    plot_importance(feat_importance_cons, string, save = SAVEFIGS, cons = True)\n",
    "    if SEPARATE_CLASSIFIER:\n",
    "        plot_importance(feat_importance_prod, string, save = SAVEFIGS, cons = False)\n",
    "    \n",
    "    for result, measure_name in zip(all_results, measure_names):\n",
    "        result.describe()\n",
    "        plot_results(result, measure_name, False, string, save = SAVEFIGS)\n",
    "\n",
    "    if not TRAIN_ON_SUM:\n",
    "        string2 = AL_switcher.get(AL_METHOD).__name__ + \"_\"  + weight + old + bdwidth + learners_qbc + sep_class + train + \"single_\" + samp_ratio + str(N_QUERIES)\n",
    "        for result, measure_name in zip(all_results_single, measure_names):\n",
    "            result.describe()\n",
    "            plot_results(result, measure_name, True, string2, save = SAVEFIGS)\n",
    "    \n",
    "    if SAVERATIO:\n",
    "        np.savetxt(\"../Figures/\" + string  + \".txt\", balance_ratios.describe(), delimiter=', ', fmt='%1.4f')\n",
    "        \n",
    "    if SAVERESULTS and TRAIN_ON_SUM:\n",
    "        for result, measure_name in zip(all_results, measure_names):\n",
    "            result.to_pickle(\"../Results/\" + string + \"_\" + measure_name + \".pkl\")    \n",
    "        trajectory_selection_frequencies.to_pickle(\"../Results/\" + string + \"_freq.pkl\")\n",
    "        \n",
    "        feat_importance_cons.to_pickle(\"../Results/\" + string + \"_feat_imp_cons\" + \".pkl\")\n",
    "        if SEPARATE_CLASSIFIER:\n",
    "            feat_importance_prod.to_pickle(\"../Results/\" + string + \"_feat_imp_prod\" + \".pkl\")\n",
    "            \n",
    "    if SAVERESULTS and not TRAIN_ON_SUM:\n",
    "        for result, measure_name in zip(all_results, measure_names):\n",
    "            result.to_pickle(\"../Results/\" + string + \"_\" + measure_name + \".pkl\")    \n",
    "        trajectory_selection_frequencies.to_pickle(\"../Results/\" + string + \"_freq.pkl\")\n",
    "        \n",
    "        for result, measure_name in zip(all_results_single, measure_names):\n",
    "            result.to_pickle(\"../Results/\" + string2 + \"_\" + measure_name + \".pkl\")   \n",
    "        \n",
    "        feat_importance_cons.to_pickle(\"../Results/\" + string + \"_feat_imp_cons\" + \".pkl\")\n",
    "        if SEPARATE_CLASSIFIER:\n",
    "            feat_importance_prod.to_pickle(\"../Results/\" + string + \"_feat_imp_prod\" + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting execution:  1 / 3 - - - - - - - - \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6f3be56f4ab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m run_openml_test(data=X,k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n\u001b[0;32m      2\u001b[0m              \u001b[0mml_method_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_sep_method_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mal_method_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqbc_learners_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_qbc_learners_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-903e467fc1ea>\u001b[0m in \u001b[0;36mrun_openml_test\u001b[1;34m(data, k_, execs_, n_queries_, n_init_, train_sum_, sep_class_, ml_method_, ml_sep_method_, al_method_, qbc_learners_, n_qbc_learners_, weighting_factor_, save_figs_, save_ratio_, save_results_, time_point, bandwidth_, pal_priors, sc_pca_)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting execution: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mEXECUTIONS\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;34m\"- - - - - - - - \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0munique_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mn_labeled_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "run_openml_test(data=X,k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running cross-validation of classifier and active learning approach. May be executed multiple times to combat the variability of performance at specific points during training\n",
    "# Dataframes are converted to numpy arrays before using with modAL leaners because that is what they expect. These conversions are done throughout the process when necessary.\n",
    "# The main dataframes (looping and looping_sum) are assumed to be globally set, the other settings correspond to those as defined above.\n",
    "def run_test(k_, execs_, n_queries_, n_init_, train_sum_, sep_class_, ml_method_, ml_sep_method_, al_method_, qbc_learners_, n_qbc_learners_, weighting_factor_, save_figs_, save_ratio_, save_results_, time_point = None, bandwidth_ = 0, pal_priors = 1, sc_pca_ = True):\n",
    "    # Seed to allow different AL methods to train and test with the same splits and initialization sets over the course of the same number of executions with the same settings.\n",
    "    np.random.seed(0)\n",
    "    # Call the set_settings method to change settings as defined by the parameters of this method.\n",
    "    set_settings(k_, execs_, n_queries_, n_init_, train_sum_, sep_class_, ml_method_, ml_sep_method_, al_method_, qbc_learners_, n_qbc_learners_, weighting_factor_, save_figs_, save_ratio_, save_results_, bandwidth_, sc_pca_)\n",
    "    \n",
    "    # Keep track of results for each query. Used later to calculate incremental performance. +1 because the first value is the performance directly after initialization\n",
    "    accuracy_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    macro_f1_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    recall_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    precision_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    auc_results = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "\n",
    "    # Keep track of results for each query. Used later to calculate incremental performance. +1 because the first value is the performance directly after initialization\n",
    "    accuracy_results_single = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    macro_f1_results_single = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    recall_results_single = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    precision_results_single = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    auc_results_single = pd.DataFrame(columns = range(N_QUERIES + 1))\n",
    "    \n",
    "    # Keep track of feature importance during training. \n",
    "    feat_importance_cons = pd.DataFrame([], columns = range(N_QUERIES + 1), index = range(EXECUTIONS * K))\n",
    "    if SEPARATE_CLASSIFIER:\n",
    "        feat_importance_prod = pd.DataFrame([], columns = range(N_QUERIES + 1), index = range(EXECUTIONS * K))\n",
    "\n",
    "    # Keep track of label ratio in data and selected label ratio\n",
    "    balance_ratios = pd.DataFrame(columns = [\"Training Folds Ratio\", \"Selected Training Instances Ratio\"])\n",
    "    selected_instances_table = pd.DataFrame(columns = range(N_QUERIES))\n",
    "\n",
    "    # Keep track of selection frequencies of individual trajectories\n",
    "    trajectory_selection_frequencies = pd.DataFrame(0, index=range(N_QUERIES), columns = looping_sum[trajectory])\n",
    "\n",
    "    # Compute weighting factors for when instance weighting is selected.\n",
    "    non_target_weight = np.unique(compute_sample_weight('balanced', looping_sum[target]), return_counts=True)[0][0] * (2-WEIGHTING_FACTOR)\n",
    "    target_weight = np.unique(compute_sample_weight('balanced', looping_sum[target]), return_counts=True)[0][1] * WEIGHTING_FACTOR\n",
    "    \n",
    "    if time_point != None:\n",
    "        # Convert hours to seconds when evaluating partial trajectories\n",
    "        time_point = time_point * 3600\n",
    "    \n",
    "    # Perform K-fold validation for EXECUTIONS number of times. This gives more total repetitions, and thus a smoother view of learning performance\n",
    "    for execs in range(EXECUTIONS):\n",
    "        full_df = looping\n",
    "        if time_point == None:\n",
    "            df = looping_sum\n",
    "        else:\n",
    "            time_sepcific_idx = looping.groupby([\"trip_id\"]).apply(lambda x: abs(x[\"time_elapsed_s\"] - time_point)).groupby([\"trip_id\"]).idxmin().apply(lambda x: x[1])\n",
    "            df = looping.iloc[time_sepcific_idx].reset_index(drop=True)\n",
    "\n",
    "        print(\"Starting execution: \", execs+1, \"/\" , EXECUTIONS,  \"- - - - - - - - \")\n",
    "\n",
    "        unique_classes = df[target].unique()\n",
    "        n_labeled_examples = df.shape[0]\n",
    "\n",
    "        if len(unique_classes) > INITIALIZATION_SET:\n",
    "            print(\"INCREASE SIZE OF INITIALIZATION SET TO INCLUDE AT LEAST ONE INSTANCE OF EACH CLASS\")\n",
    "            raise\n",
    "        \n",
    "        # Make random selection for initialization set based on the sampling ratio and initialization set size\n",
    "        n_minority = math.ceil(int(INITIALIZATION_SET * SAMPLING_RATIO))\n",
    "        n_majority = INITIALIZATION_SET - n_minority\n",
    "        \n",
    "        initialization_indices = np.hstack([df[df[target]==NUM_TARGET].sample(n=n_minority, replace=False).index, \\\n",
    "                                                 df[df[target]!=NUM_TARGET].sample(n=n_majority, replace=False).index])\n",
    "        initialization_set = df.iloc[initialization_indices]\n",
    "\n",
    "        # Isolate the non-initialization examples to make up the sampling pool.\n",
    "        df = df.drop(df.index[initialization_indices]).reset_index(drop=True)\n",
    "\n",
    "        # Create separate set of initialization indices if using full trajectories for training\n",
    "        if not TRAIN_ON_SUM:\n",
    "            full_initialization_set = pd.DataFrame(columns = full_df.columns)\n",
    "\n",
    "            for unique_trajectory in initialization_set[trajectory].unique():\n",
    "                # Retrieve all instances with this trajectory id from full data set\n",
    "                full_initialization_set = full_initialization_set.append(full_df[full_df[trajectory] == unique_trajectory])\n",
    "\n",
    "            # Split into X and y\n",
    "            X_initialize = full_initialization_set.drop(target, axis=1).reset_index(drop=True)\n",
    "            y_initialize = full_initialization_set[target].reset_index(drop=True)\n",
    "            del(full_initialization_set)\n",
    "        else:\n",
    "            # Labeled training instances.\n",
    "            X_initialize = initialization_set.drop(target, axis=1).reset_index(drop=True)\n",
    "            y_initialize = initialization_set[target].reset_index(drop=True)\n",
    "            \n",
    "        # labeled training instances.\n",
    "        X_aggr_initialize = initialization_set.drop(target, axis=1).reset_index(drop=True)\n",
    "        y_aggr_initialize = initialization_set[target].reset_index(drop=True)\n",
    "\n",
    "        X_initialize[trajectory] = X_initialize[trajectory].apply(pd.to_numeric)\n",
    "        y_initialize = pd.to_numeric(y_initialize)\n",
    "\n",
    "        # Take stratified folds to make sure each fold contains enough instances of the majority class\n",
    "        skf = StratifiedKFold(n_splits=K, shuffle = True)\n",
    "        \n",
    "        if time_point != None:\n",
    "            pretime_df, ontime_df = time_specific_summarized_set(df, time_point, 30)\n",
    "    \n",
    "            X_aggr = ontime_df.drop(target, axis=1).to_numpy()\n",
    "            y_aggr = ontime_df[target].to_numpy()\n",
    "            train_set_indices = np.array(list(skf.split(X_aggr, y_aggr)))\n",
    "            \n",
    "        else:\n",
    "            # Split aggregated instances into X and y\n",
    "            X_aggr = df.drop(target, axis=1).to_numpy()\n",
    "            y_aggr = df[target].to_numpy()\n",
    "            train_set_indices = np.array(list(skf.split(X_aggr, y_aggr)))\n",
    "\n",
    "        # K-fold cross validation\n",
    "        for i in range(K):\n",
    "            print(\"Validating on fold: \", i+1 , \"/\", K, end=\"\\r\")\n",
    "            # Set train and test set for current fold\n",
    "            if time_point != None:\n",
    "                X_train = np.vstack([X_aggr[train_set_indices[i][0]], pretime_df.drop(target, axis=1).to_numpy()])\n",
    "                y_train = np.hstack([y_aggr[train_set_indices[i][0]], pretime_df[target].to_numpy()])\n",
    "        \n",
    "                X_test = X_aggr[train_set_indices[i][1]]\n",
    "                y_test = y_aggr[train_set_indices[i][1]]\n",
    "        \n",
    "            else: \n",
    "                X_train = X_aggr[train_set_indices[i][0]]\n",
    "                y_train = y_aggr[train_set_indices[i][0]]\n",
    "                \n",
    "                X_test = X_aggr[train_set_indices[i][1]]\n",
    "                y_test = y_aggr[train_set_indices[i][1]]\n",
    "            \n",
    "            # If the training set has fewer instances than the selected query budget, we have too few instances\n",
    "            if len(X_train) < N_QUERIES:\n",
    "                print(\"TOO FEW TRAINING INSTANCES TO TRAIN THIS FAR. REDUCE TO \", len(X_train))\n",
    "                raise\n",
    "            \n",
    "            # This is why the trajectory identifier needs to be the first column. For creating the folds the dataframe needs to be turned into a numpy array,\n",
    "            # but because of this the ability to select based on name is lost when we try to find these identifiers later.\n",
    "            unique_train_trajectories = np.unique(X_train[:,0])\n",
    "            unique_test_trajectories = np.unique(X_test[:,0])\n",
    "            unique_initialization_trajectories = X_initialize[trajectory].unique()\n",
    "            \n",
    "            fold_full_df = full_df[full_df[trajectory].isin(np.concatenate([unique_initialization_trajectories, unique_train_trajectories, unique_test_trajectories]))]\n",
    "            \n",
    "            # Line only needed when testing without PCA and scaling, but doesn't do harm when not using PCA or scaling\n",
    "            fold_X_initialize = X_initialize\n",
    "\n",
    "            # Currently PCA commented out due to performance decrease for testing during the project. Can be uncommented to inlude PCA again\n",
    "            if SC_PCA:\n",
    "                # Initialization of SC and PCA:\n",
    "                sc = StandardScaler()\n",
    "                pca = PCA(n_components=0.9)\n",
    "\n",
    "                # If training with all trajectory instance, need to scale and fit for this separately from the summarized dataset\n",
    "                if not TRAIN_ON_SUM:\n",
    "                    sc.fit(fold_full_df[fold_full_df[trajectory].isin(unique_train_trajectories)].drop(trajectory,axis=1).drop(target,axis=1))\n",
    "                    fold_full_df = fold_full_df[[trajectory, target]].join(pd.DataFrame(sc.transform(fold_full_df.drop(trajectory,axis=1).drop(target,axis=1)), \\\n",
    "                                                                                            columns=fold_full_df.columns[2:], index=fold_full_df.index))\n",
    "#                     pca.fit(fold_full_df[fold_full_df[trajectory].isin(unique_train_trajectories)].drop(trajectory,axis=1).drop(target,axis=1))\n",
    "#                     fold_full_df = fold_full_df[[trajectory, target]].join(pd.DataFrame(pca.transform(fold_full_df.drop(trajectory,axis=1).drop(target,axis=1)), \\\n",
    "#                                                                                             columns=['PCA%i' %  i for i in range(len(pca.components_))], index=fold_full_df.index))\n",
    "\n",
    "                    # if not using a separte classifier, need to apply same scaling and PCA of full dataset to the summarized one so training and predictions sets don't have different features\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        X_train[:,1:] = sc.transform(X_train[:,1:])\n",
    "                        X_test[:,1:] = sc.transform(X_test[:,1:])\n",
    "                        X_initialize_values = X_initialize.drop(trajectory,axis=1)\n",
    "                        X_initialize_values = pd.DataFrame(sc.transform(X_initialize_values), columns=X_initialize_values.columns, index=X_initialize_values.index)\n",
    "                        fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "\n",
    "#                         X_train = np.hstack((X_train[:,0,np.newaxis], pca.transform(X_train[:,1:])))\n",
    "#                         X_test = np.hstack((X_test[:,0,np.newaxis], pca.transform(X_test[:,1:])))\n",
    "#                         X_initialize_values = fold_X_initialize.drop(trajectory,axis=1)\n",
    "#                         X_initialize_values = pd.DataFrame(pca.transform(X_initialize_values), columns=['PCA%i' %  i for i in range(len(pca.components_))], index=X_initialize_values.index)\n",
    "#                         fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "                    else:\n",
    "                        X_train[:,1:] = sc.fit_transform(X_train[:,1:])\n",
    "                        X_test[:,1:] = sc.transform(X_test[:,1:])\n",
    "                        X_initialize_values = X_initialize.drop(trajectory,axis=1)\n",
    "                        X_initialize_values = pd.DataFrame(sc.transform(X_initialize_values), columns=X_initialize_values.columns, index=X_initialize_values.index)\n",
    "                        fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "\n",
    "#                         X_train = np.hstack((X_train[:,0,np.newaxis], pca.fit_transform(X_train[:,1:])))\n",
    "#                         X_test = np.hstack((X_test[:,0,np.newaxis], pca.transform(X_test[:,1:])))\n",
    "#                         X_initialize_values = fold_X_initialize.drop(trajectory,axis=1)\n",
    "#                         X_initialize_values = pd.DataFrame(pca.transform(X_initialize_values), columns=['PCA%i' %  i for i in range(len(pca.components_))], index=X_initialize_values.index)\n",
    "#                         fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "                else:\n",
    "                    X_train[:,1:] = sc.fit_transform(X_train[:,1:])\n",
    "                    X_test[:,1:] = sc.transform(X_test[:,1:])\n",
    "                    X_initialize_values = X_initialize.drop(trajectory,axis=1)\n",
    "                    X_initialize_values = pd.DataFrame(sc.transform(X_initialize_values), columns=X_initialize_values.columns, index=X_initialize_values.index)\n",
    "                    fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "\n",
    "#                     X_train = np.hstack((X_train[:,0,np.newaxis], pca.fit_transform(X_train[:,1:])))\n",
    "#                     X_test = np.hstack((X_test[:,0,np.newaxis], pca.transform(X_test[:,1:])))\n",
    "#                     X_initialize_values = fold_X_initialize.drop(trajectory,axis=1)\n",
    "#                     X_initialize_values = pd.DataFrame(pca.transform(X_initialize_values), columns=['PCA%i' %  i for i in range(len(pca.components_))], index=X_initialize_values.index)\n",
    "#                     fold_X_initialize = pd.DataFrame(X_initialize[trajectory]).join(X_initialize_values)\n",
    "            \n",
    "            # Backup that allows for multiple ways of using the same y_test name but handling performance measures in different ways\n",
    "            y_test_original = y_test\n",
    "\n",
    "            if OVERSAMPLE and UNDERSAMPLE:\n",
    "                print(\"CAN'T UNDER AND OVERSAMPLE AT THE SAME TIME\")\n",
    "                raise\n",
    "            if OVERSAMPLE:\n",
    "                sampler = RandomOverSampler(sampling_strategy=SAMPLING_RATIO)\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "            elif UNDERSAMPLE:\n",
    "                sampler = RandomUnderSampler(sampling_strategy=SAMPLING_RATIO)\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Save class ratio of instances in training fold\n",
    "            fold_training_ratio = np.count_nonzero(y_train == NUM_TARGET)/np.count_nonzero(y_train != NUM_TARGET) # MOSTLY MAKES SENSE FOR BINARY TARGET CLASS\n",
    "\n",
    "            model = ML_switcher.get(ML_METHOD)\n",
    "\n",
    "            if AL_METHOD == 5 and not SEPARATE_CLASSIFIER: # Using QBC for main classifier, NOT RECOMMENDED WHEN COMPARING AL METHODS\n",
    "                committee_list = []\n",
    "                unique_trajectories_init = fold_X_initialize[trajectory].unique()\n",
    "                qbc_initialization_size = math.ceil(INITIALIZATION_SET/(N_QBC_LEARNERS*len(QBC_LEARNERS))) + 1\n",
    "                \n",
    "                # For each specified QBC member, create N_QBC_LEARNERS learners to be added to the committee\n",
    "                for qbc_model in QBC_LEARNERS:\n",
    "                    # select random numbers, find trip id's for these in the aggr dataset. Then select all instances with these id's from the initilizing set and use them as new initializing set\n",
    "                    for n in range(N_QBC_LEARNERS):\n",
    "                        original_estimator = ML_switcher.get(qbc_model)\n",
    "                        new_estimator = deepcopy(original_estimator)\n",
    "                        \n",
    "                        # The number of items for initializing the committe members is the proportion of number of members to size of the initialization set, rounded up.\n",
    "                        # Considering the initialization set is usually small in this case due to low amounts of data, replacement is allowed which results insome overlap \n",
    "                        # in intialization sets make random selection for initialization set based on the sampling ratio and initialization set size\n",
    "                        n_minority = math.ceil(int(qbc_initialization_size * SAMPLING_RATIO)) + 1\n",
    "                        n_majority = qbc_initialization_size - n_minority\n",
    "\n",
    "                        unique_negative_target = np.random.choice(initialization_set[initialization_set[target] != NUM_TARGET][trajectory].unique(),n_majority,replace=True)\n",
    "                        unique_positive_target = np.random.choice(initialization_set[initialization_set[target] == NUM_TARGET][trajectory].unique(),n_minority,replace=True)\n",
    "                        trajectories_init = np.concatenate((unique_positive_target, unique_negative_target), axis=None)\n",
    "                        \n",
    "                        idx_member_init = fold_X_initialize.index[fold_X_initialize[trajectory].isin(trajectories_init)].to_numpy()\n",
    "\n",
    "                        X_member_init = fold_X_initialize.iloc[idx_member_init].to_numpy()\n",
    "                        y_member_init = y_initialize.iloc[idx_member_init].to_numpy()\n",
    "\n",
    "                        # Initializing learner\n",
    "                        committee_member =  ActiveLearner(\n",
    "                            estimator=new_estimator,\n",
    "                            X_training=X_member_init, y_training=y_member_init\n",
    "                        )\n",
    "                        committee_list.append(committee_member)\n",
    "\n",
    "                # Assembling the committee\n",
    "                learner = Committee(\n",
    "                    learner_list=committee_list,\n",
    "                    query_strategy=QBC_STRATEGY\n",
    "                )\n",
    "            else: # NOT using QBC for main classifier. Should pretty much be always the case\n",
    "                # Specify the core estimator along with its active learning model. Fit with the labeled data set\n",
    "                learner = ActiveLearner(\n",
    "                    estimator=deepcopy(model),\n",
    "                    query_strategy=AL_switcher.get(AL_METHOD),\n",
    "                    X_training=fold_X_initialize.to_numpy(), y_training=y_initialize.to_numpy()\n",
    "                )\n",
    "\n",
    "            # Create separate classifer for training and estimation\n",
    "            if SEPARATE_CLASSIFIER:\n",
    "                query_model = deepcopy(ML_switcher.get(ML_SEP_METHOD))\n",
    "                new_query_strategy = deepcopy(AL_switcher.get(AL_METHOD))\n",
    "\n",
    "                if AL_METHOD != 5:\n",
    "                    query_estimator = ActiveLearner(\n",
    "                            estimator=query_model,\n",
    "                            query_strategy=new_query_strategy,\n",
    "                            X_training=X_aggr_initialize.to_numpy(), y_training=y_aggr_initialize.to_numpy()\n",
    "                    )\n",
    "                else:\n",
    "                    committee_list = []\n",
    "                    unique_trajectories_init = X_aggr_initialize[trajectory].unique()\n",
    "                    qbc_initialization_size = math.ceil(INITIALIZATION_SET/(N_QBC_LEARNERS*len(QBC_LEARNERS)))+1\n",
    "                    \n",
    "                    # For each specified QBC member, create N_QBC_LEARNERS learners to be added to the committee\n",
    "                    for qbc_model in QBC_LEARNERS:\n",
    "                        \n",
    "                        # select random numbers, find trip id's for these in the aggr dataset. Then select all instances with these id's from the initilizing set and use them as new initializing set\n",
    "                        for n in range(N_QBC_LEARNERS):\n",
    "                            original_estimator = deepcopy(ML_switcher.get(qbc_model))\n",
    "                            new_estimator = deepcopy(original_estimator)\n",
    "                            \n",
    "                            # make random selection for initialization set based on the sampling ratio and initialization set size\n",
    "                            n_minority = math.ceil(int(qbc_initialization_size * SAMPLING_RATIO)) + 1\n",
    "                            n_majority = qbc_initialization_size - n_minority\n",
    "\n",
    "                            unique_negative_target = np.random.choice(initialization_set[initialization_set[target] != NUM_TARGET][trajectory].unique(),n_majority,replace=False)\n",
    "                            unique_positive_target = np.random.choice(initialization_set[initialization_set[target] == NUM_TARGET][trajectory].unique(),n_minority,replace=False)\n",
    "                            \n",
    "                            trajectories_init = np.hstack([unique_positive_target, unique_negative_target])\n",
    "\n",
    "                            idx_member_init = X_aggr_initialize[X_aggr_initialize[trajectory].isin(trajectories_init)].index.to_numpy()\n",
    "\n",
    "                            X_member_init = X_aggr_initialize.iloc[idx_member_init].to_numpy()\n",
    "                            y_member_init = y_aggr_initialize.iloc[idx_member_init].to_numpy()\n",
    "\n",
    "                            # initializing learner\n",
    "                            committee_member =  ActiveLearner(\n",
    "                                estimator=new_estimator,\n",
    "                                X_training=X_member_init, y_training=y_member_init\n",
    "                            )\n",
    "                            committee_list.append(committee_member)\n",
    "\n",
    "                    # Assembling the committee\n",
    "                    query_estimator = Committee(\n",
    "                        learner_list=committee_list,\n",
    "                        query_strategy=vote_entropy_sampling\n",
    "                    )\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "            # Make first set of predictions (before querying)\n",
    "            predictions = []\n",
    "\n",
    "            if TRAIN_ON_SUM:\n",
    "                predictions = learner.predict(X_test)\n",
    "\n",
    "            else:\n",
    "                # Training with all instances performance 1: Evaluating performance only for the summarizing instance (in this case single point at end of trajectory)\n",
    "                predictions_single = learner.predict(X_test)\n",
    "\n",
    "                unqueried_score_single = accuracy_score(y_test, predictions_single)\n",
    "                unqueried_macro_f1_single = f1_score(y_test, predictions_single, average='macro')\n",
    "                unqueried_recall_single = recall_score(y_test, predictions_single, average='macro')\n",
    "                unqueried_precision_single = precision_score(y_test, predictions_single, average='macro', zero_division=0)\n",
    "                unqueried_auc_single = roc_auc_score(y_test, predictions_single, average = 'macro')\n",
    "\n",
    "                # Store performance of every calculated score\n",
    "                accuracy_history_single = [unqueried_score_single]\n",
    "                macro_f1_history_single = [unqueried_macro_f1_single]\n",
    "                recall_history_single = [unqueried_recall_single]\n",
    "                precision_history_single = [unqueried_precision_single]\n",
    "                auc_history_single = [unqueried_auc_single]\n",
    "\n",
    "                # Training with all instances performance 2: Evaluate performance by classifying all individual instances of each trajectory and taking a majority vote to get a \n",
    "                # prediction for that one trajectory.\n",
    "                y_test = []\n",
    "                for unique_trajectory in unique_test_trajectories:\n",
    "                    # Retrieve all instances with this trajectory id from full data set\n",
    "                    test_trajectory_full = fold_full_df[fold_full_df[trajectory] == unique_trajectory]\n",
    "                    # Split into numpy X and y\n",
    "                    X_test_full = test_trajectory_full.drop(target, axis=1).to_numpy()\n",
    "\n",
    "                    y_test.append(test_trajectory_full[target].to_numpy()[0])\n",
    "                    del(test_trajectory_full)\n",
    "\n",
    "                    # get prediction of one trajectory via majority vote of all its inividual instance classifications\n",
    "                    trajectory_prediction = np.bincount(learner.predict(X_test_full).astype(int)).argmax() # not sure why this has to be cast as int, already should be\n",
    "\n",
    "                    # append prediction to a list\n",
    "                    predictions.append(trajectory_prediction)\n",
    "                del(X_test_full)\n",
    "\n",
    "            # Record our learner's performance on the test data\n",
    "            unqueried_score = accuracy_score(y_test, predictions)\n",
    "            unqueried_macro_f1 = f1_score(y_test, predictions, average='macro')\n",
    "            unqueried_recall = recall_score(y_test, predictions, average='macro')\n",
    "            unqueried_precision = precision_score(y_test, predictions, average='macro', zero_division=0)\n",
    "            unqueried_auc = roc_auc_score(y_test, predictions, average = 'macro')\n",
    "\n",
    "            # Store performance of every calculated score\n",
    "            accuracy_history = [unqueried_score]\n",
    "            macro_f1_history = [unqueried_macro_f1]\n",
    "            recall_history = [unqueried_recall]\n",
    "            precision_history = [unqueried_precision]\n",
    "            auc_history = [unqueried_auc]\n",
    "\n",
    "            # Store feature importance.  For QBC, average importances of all committe members taken (although the differences between the members could be interesting)\n",
    "            if AL_METHOD != 5:\n",
    "                if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                    feat_importance_cons.iat[0,0] = abs(learner.estimator.coef_)[0]\n",
    "                else:\n",
    "                    feat_importance_cons.iat[0,0] = learner.estimator.feature_importances_\n",
    "                if SEPARATE_CLASSIFIER:\n",
    "                    if query_estimator.estimator.__class__.__name__ == \"SVC\" or query_estimator.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                        feat_importance_prod.iat[0,0] = abs(query_estimator.estimator.coef_)[0]\n",
    "                    else:\n",
    "                        feat_importance_prod.iat[0,0] = query_estimator.estimator.feature_importances_\n",
    "            else:\n",
    "                if not SEPARATE_CLASSIFIER:    \n",
    "                    feat_importance_cons.iat[0,0] = 0\n",
    "                    for member in learner:\n",
    "                        if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                            feat_importance_cons.iat[0,0] += abs(member.estimator.coef_)[0]\n",
    "                        else:\n",
    "                            feat_importance_cons.iat[0,0] += member.estimator.feature_importances_\n",
    "                        feat_importance_cons.iat[0,0] = feat_importance_cons.iat[0,0] / len(learner)\n",
    "                else:\n",
    "                    if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                        feat_importance_cons.iat[0,0] = abs(learner.estimator.coef_)[0]\n",
    "                    else:\n",
    "                        feat_importance_cons.iat[0,0] = learner.estimator.feature_importances_\n",
    "\n",
    "                    feat_importance_prod.iat[0,0] = 0\n",
    "                    for member in query_estimator:\n",
    "                        if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                            feat_importance_prod.iat[0,0] += abs(member.estimator.coef_)[0]\n",
    "                        else:\n",
    "                            feat_importance_prod.iat[0,0] += member.estimator.feature_importances_\n",
    "                        feat_importance_prod.iat[0,0] = feat_importance_prod.iat[0,0] / len(query_estimator)\n",
    "            \n",
    "            # Labels of selected training instances. Used for calculating metrics later on\n",
    "            selected_training_instance_labels = np.array([])\n",
    "            \n",
    "            \n",
    "            # For PAL: calculating gamma through bandwidth, with mean as default and using rbf as the kernel\n",
    "            nominator = 2 * len(X_test) * len(X_test[0]) # number of instances, number of features\n",
    "            denominator = (len(X_test) - 1) * np.log((len(X_test) - 1) / ((np.sqrt(2) * 10 ** -6) ** 2))\n",
    "            bandwidth = np.sqrt(nominator / denominator)\n",
    "            \n",
    "            if BANDWIDTH == 0:\n",
    "                bandwidth = np.sqrt(nominator / denominator)\n",
    "            else: bandwidth = BANDWIDTH\n",
    "            \n",
    "            gamma = 0.5 * (bandwidth ** (-2))\n",
    "            \n",
    "            # Perform training and testing for the budget of N_QUERIES. The \"unlabeled\" dataset is queried for the most informative points according to our query strategy\n",
    "            # which are consecutively added to the training set after which performance is directly measured.\n",
    "            for index in range(N_QUERIES):\n",
    "                # Setting up kernel with rbf as default and additional parameters (for PAL and xPAL)\n",
    "                params = {}\n",
    "                if AL_METHOD == 6 or AL_METHOD == 7 or AL_METHOD == 8 or AL_METHOD == 9:\n",
    "                    S =  pairwise_kernels(X = X_train, Y = X_train, metric='rbf', gamma=gamma)\n",
    "                    S = check_array(S, np.eye(len(X_train)))\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        params = {'n_classes': len(unique_classes), \"labeled_instances\": query_estimator.X_training, \"labels\": query_estimator.y_training, \"kernel\": S, \"priors\": pal_priors}\n",
    "                    else: \n",
    "                        params = {'n_classes': len(unique_classes), \"labeled_instances\": learner.X_training, \"labels\": learner.y_training, \"kernel\": S, \"priors\": pal_priors}\n",
    "\n",
    "                # Query instance using AL method\n",
    "                if SEPARATE_CLASSIFIER:\n",
    "                    query_index, query_instance = query_estimator.query(X_train, **params)\n",
    "                else:\n",
    "                    query_index, query_instance = learner.query(X_train, **params)\n",
    "\n",
    "                # For measuring frequencies of selection of specific trajectories over the course of learning\n",
    "                trajectory_selection_frequencies.iloc[index][int(X_train[query_index,0])] += 1\n",
    "                \n",
    "                # For measuring performance in terms of label selection\n",
    "                selected_training_instance_labels = np.append(selected_training_instance_labels, y_train[query_index])\n",
    "\n",
    "                # logic to make sure only do additional bootstrapping when using qbc, and only on the QBC classifiers\n",
    "                boot_main = False\n",
    "                boot_sep = False\n",
    "#                 # This currently breaks. The bootstrapping takes random samples, but there are too few in the initialization set to guarantee at least one of each class\n",
    "#                 if AL_METHOD == 5:\n",
    "#                     if SEPARATE_CLASSIFIER:\n",
    "#                         boot_main = False\n",
    "#                         boot_sep = True\n",
    "#                     else:\n",
    "#                         boot_main = True\n",
    "#                         boot_sep = True\n",
    "                \n",
    "                # Setting weighting of training instances when not randomly selecting them. Using two arrays guarantees that no overlapping values erase each other\n",
    "                if WEIGHTING_FACTOR != 0 and AL_METHOD != 1 and AL_METHOD != 5:\n",
    "                    current_labels = np.append(learner.y_training, y_train[query_index].reshape(1, ))\n",
    "                    sample_weights = np.zeros(len(current_labels)).astype(float)\n",
    "                    temp_indices = np.where(current_labels == NUM_TARGET)\n",
    "                    sample_weights[temp_indices] = target_weight\n",
    "                    temp_indices = np.where(current_labels != NUM_TARGET)\n",
    "                    sample_weights[temp_indices] = non_target_weight\n",
    "                else:\n",
    "                    sample_weights = None\n",
    "    \n",
    "        \n",
    "                # Training the consumer with the summarizing queried instance\n",
    "                if TRAIN_ON_SUM:\n",
    "                    # Train our ActiveLearner model with the instance it has requested.\n",
    "                    X_temp, y_temp = X_train[query_index].reshape(1, -1), y_train[query_index].reshape(1, )\n",
    "                    learner.teach(X=X_temp, y=y_temp, bootstrap=boot_main, sample_weight = sample_weights)\n",
    "\n",
    "                    # Training a separate classifier (producer) with the summarizing queried instance\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        X_temp, y_temp = X_train[query_index].reshape(1, -1), y_train[query_index].reshape(1, )\n",
    "                        query_estimator.teach(X=X_temp, y=y_temp, bootstrap=boot_sep, sample_weight = sample_weights)\n",
    "\n",
    "                # Training the model with all instances of queried trip\n",
    "                else:\n",
    "                    # Training a separate classifier (producer) used for selecting queries\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                        X_temp, y_temp = X_train[query_index].reshape(1, -1), y_train[query_index].reshape(1, )\n",
    "                        \n",
    "                        if WEIGHTING_FACTOR != 0 and AL_METHOD != 1 and AL_METHOD != 5:\n",
    "                            current_labels = np.append(query_estimator.y_training, y_train[query_index].reshape(1, ))\n",
    "                            sample_weights = np.zeros(len(current_labels)).astype(float)\n",
    "                            temp_indices = np.where(current_labels == NUM_TARGET)\n",
    "                            sample_weights[temp_indices] = target_weight\n",
    "                            temp_indices = np.where(current_labels != NUM_TARGET)\n",
    "                            sample_weights[temp_indices] = non_target_weight\n",
    "                        else:\n",
    "                            sample_weights = None\n",
    "                        \n",
    "                        query_estimator.teach(X=X_temp, y=y_temp, bootstrap = boot_sep, sample_weight = sample_weights)\n",
    "\n",
    "                    # Find trip_id of selected query in aggregated instances\n",
    "                    query_trajectory_id = X_train[query_index,0]\n",
    "                    # Retrieve all instances with this trajectory id from full data set\n",
    "\n",
    "                    if not isinstance(query_trajectory_id, float):\n",
    "                        query_trajectory_id = query_trajectory_id[0]\n",
    "                    query_trajectory_full = fold_full_df[fold_full_df[trajectory] == query_trajectory_id] # for sep classifier the specific formatting returns one element in two dimensions\n",
    "\n",
    "                    # Split into numpy X and y\n",
    "                    X_train_full = query_trajectory_full.drop(target, axis=1).to_numpy()\n",
    "                    y_train_full = query_trajectory_full[target].to_numpy()\n",
    "                    del(query_trajectory_full)\n",
    "\n",
    "                    if WEIGHTING_FACTOR != 0 and AL_METHOD != 1 and AL_METHOD != 5:\n",
    "                        current_labels = np.append(learner.y_training, y_train_full)\n",
    "                        sample_weights = np.zeros(len(current_labels)).astype(float)\n",
    "                        temp_indices = np.where(current_labels == NUM_TARGET)\n",
    "                        sample_weights[temp_indices] = target_weight\n",
    "                        temp_indices = np.where(current_labels != NUM_TARGET)\n",
    "                        sample_weights[temp_indices] = 1 - (non_target_weight * 0.1)\n",
    "                    else:\n",
    "                        sample_weights = None\n",
    "                    \n",
    "                    # Add selected instances to training pool and teach the model re-train the model on the new set\n",
    "                    # Train the consumer on either the full or \n",
    "                    learner.teach(X=X_train_full, y=y_train_full, bootstrap=boot_main, sample_weight = sample_weights)\n",
    "\n",
    "                    del(X_train_full)\n",
    "                    del(y_train_full)\n",
    "\n",
    "                # Remove the queried instance from the unlabeled pool.\n",
    "                X_train, y_train = np.delete(X_train, query_index, axis=0), np.delete(y_train, query_index)\n",
    "\n",
    "                predictions = []\n",
    "                # Evluate performance of\n",
    "                if TRAIN_ON_SUM:\n",
    "                    # Make predictions\n",
    "                    predictions = learner.predict(X_test)\n",
    "\n",
    "                # Evaluate performance on full trajectories by classifying all individual instances of each trajectory and taking a majority vote to get a prediction for that one trajectory\n",
    "                else:\n",
    "                    predictions_single = learner.predict(X_test)\n",
    "\n",
    "                    # Calculate and report our model's accuracy for last instance.\n",
    "                    model_accuracy_single = accuracy_score(y_test_original, predictions_single)\n",
    "                    model_macro_f1_single = f1_score(y_test_original, predictions_single, average='macro')\n",
    "                    model_recall_single = recall_score(y_test_original, predictions_single, average='macro')\n",
    "                    model_precision_single = precision_score(y_test_original, predictions_single, average='macro', zero_division=0) # zero_division because sometimes no preictions of looping class\n",
    "                    model_auc_single = roc_auc_score(y_test_original, predictions_single, average = 'macro')\n",
    "                    \n",
    "                    accuracy_history_single.append(model_accuracy_single)\n",
    "                    macro_f1_history_single.append(model_macro_f1_single)\n",
    "                    recall_history_single.append(model_recall_single)\n",
    "                    precision_history_single.append(model_precision_single)  \n",
    "                    auc_history_single.append(model_auc_single)\n",
    "                    \n",
    "                    y_test = []\n",
    "                    for unique_trajectory in unique_test_trajectories:\n",
    "                        # Retrieve all instances with this trajectory id from full data set\n",
    "                        test_trajectory_full = fold_full_df[fold_full_df[trajectory] == unique_trajectory]\n",
    "\n",
    "                        # Split into numpy X and y\n",
    "                        X_test_full = test_trajectory_full.drop(target, axis=1).to_numpy()\n",
    "                        y_test.append(test_trajectory_full[target].to_numpy()[0])\n",
    "                        del(test_trajectory_full)\n",
    "\n",
    "                        # Get prediction of one trajectory via majority vote of all its inividual instance classifications\n",
    "                        trajectory_prediction = np.bincount(learner.predict(X_test_full).astype(int)).argmax()\n",
    "                        # append prediction to a list\n",
    "                        predictions.append(trajectory_prediction)\n",
    "\n",
    "                # Calculate and report our model's accuracy.\n",
    "                model_accuracy = accuracy_score(y_test, predictions)\n",
    "                model_macro_f1 = f1_score(y_test, predictions, average='macro')\n",
    "                model_recall = recall_score(y_test, predictions, average='macro')\n",
    "                model_precision = precision_score(y_test, predictions, average='macro', zero_division=0) # zero_division because sometimes no preictions of looping class\n",
    "                model_auc = roc_auc_score(y_test, predictions, average = 'macro')\n",
    "\n",
    "                # Save our model's performance for plotting.\n",
    "                accuracy_history.append(model_accuracy)\n",
    "                macro_f1_history.append(model_macro_f1)\n",
    "                recall_history.append(model_recall)\n",
    "                precision_history.append(model_precision)\n",
    "                auc_history.append(model_auc)\n",
    "                \n",
    "                # Store feature importance.  For the time being, taking average feature importance of QBC members, although the differences between the members should be interesting\n",
    "                if AL_METHOD != 5:\n",
    "                    if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                        feat_importance_cons.iat[execs * K + i, index+1] = abs(learner.estimator.coef_)[0]\n",
    "                    else:\n",
    "                        feat_importance_cons.iat[execs * K + i, index+1] = learner.estimator.feature_importances_\n",
    "                    if SEPARATE_CLASSIFIER:\n",
    "                            if query_estimator.estimator.__class__.__name__ == \"SVC\" or query_estimator.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] = abs(query_estimator.estimator.coef_)[0]\n",
    "                            else:\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] = query_estimator.estimator.feature_importances_\n",
    "                else:\n",
    "                    if not SEPARATE_CLASSIFIER:\n",
    "                        feat_importance_cons.iat[execs * K + i, index+1] = 0\n",
    "                        for member in learner:\n",
    "                            if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                                feat_importance_cons.iat[execs * K + i, index+1] += abs(member.estimator.coef_)[0]\n",
    "                            else:\n",
    "                                feat_importance_cons.iat[execs * K + i, index+1] += member.estimator.feature_importances_\n",
    "                            feat_importance_cons.iat[execs * K + i, index+1] = feat_importance_cons.iat[execs * K + i, index+1] / len(learner)\n",
    "                    else:\n",
    "                        if learner.estimator.__class__.__name__ == \"SVC\" or learner.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                            feat_importance_cons.iat[execs * K + i, index+1] = abs(learner.estimator.coef_)[0]\n",
    "                        else:\n",
    "                            feat_importance_cons.iat[execs * K + i, index+1] = learner.estimator.feature_importances_\n",
    "                        \n",
    "                        feat_importance_prod.iat[execs * K + i, index+1] = 0\n",
    "                        for member in query_estimator:\n",
    "                            if member.estimator.__class__.__name__ == \"SVC\" or member.estimator.__class__.__name__ == \"LogisticRegression\":\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] += abs(member.estimator.coef_)[0]\n",
    "                            else:\n",
    "                                feat_importance_prod.iat[execs * K + i, index+1] += member.estimator.feature_importances_\n",
    "                            feat_importance_prod.iat[execs * K + i, index+1] = feat_importance_prod.iat[execs * K + i, index+1] / len(query_estimator)\n",
    "                \n",
    "            # Save the class ratio over the cross validation\n",
    "            selected_training_ratio = np.count_nonzero(selected_training_instance_labels == NUM_TARGET)/ (len(selected_training_instance_labels) - np.count_nonzero(selected_training_instance_labels == NUM_TARGET))\n",
    "            series_ratios = pd.Series([fold_training_ratio, selected_training_ratio], index = balance_ratios.columns)\n",
    "            balance_ratios = balance_ratios.append(series_ratios, ignore_index=True)\n",
    "\n",
    "            # Save the specific labels chosen at each training point\n",
    "            selected_instances_table = selected_instances_table.append(pd.Series(selected_training_instance_labels), ignore_index=True)\n",
    "\n",
    "            # store results after each test\n",
    "            accuracy_results = accuracy_results.append(pd.Series(accuracy_history), ignore_index=True)\n",
    "            macro_f1_results = macro_f1_results.append(pd.Series(macro_f1_history), ignore_index=True)\n",
    "            recall_results = recall_results.append(pd.Series(recall_history), ignore_index=True)\n",
    "            precision_results = precision_results.append(pd.Series(precision_history), ignore_index=True)\n",
    "            auc_results = auc_results.append(pd.Series(auc_history), ignore_index = True)\n",
    "\n",
    "            if not TRAIN_ON_SUM:\n",
    "                accuracy_results_single = accuracy_results_single.append(pd.Series(accuracy_history_single), ignore_index=True)\n",
    "                macro_f1_results_single = macro_f1_results_single.append(pd.Series(macro_f1_history_single), ignore_index=True)\n",
    "                recall_results_single = recall_results_single.append(pd.Series(recall_history_single), ignore_index=True)\n",
    "                precision_results_single = precision_results_single.append(pd.Series(precision_history_single), ignore_index=True)\n",
    "                auc_results_single = auc_results.append(pd.Series(auc_history_single), ignore_index = True)\n",
    "            \n",
    "    # Modify selected instances table so that only the positive class is a 1, the rest is 0. This makes the average value the selected class ratio\n",
    "    # This is a problem if the target class is 0, because then all values will be set to 1.\n",
    "    # Quick workaround of first setting all non-target values to 2, then setting these to 0 after setting the target values to 1. \n",
    "    # LIKELY BREAKS WHEN NO BINARY TARGET CLASS\n",
    "    if NUM_TARGET != 0:\n",
    "        selected_instances_table[selected_instances_table != NUM_TARGET] = 0\n",
    "        selected_instances_table[selected_instances_table == NUM_TARGET] = 1\n",
    "    else:\n",
    "        selected_instances_table[selected_instances_table != NUM_TARGET] = 2\n",
    "        selected_instances_table[selected_instances_table == NUM_TARGET] = 1\n",
    "        selected_instances_table[selected_instances_table == 2] = 0\n",
    "        \n",
    "    all_results = list([macro_f1_results, recall_results, precision_results, selected_instances_table, auc_results])\n",
    "    if not TRAIN_ON_SUM:\n",
    "        all_results_single = list([macro_f1_results_single, recall_results_single, precision_results_single, selected_instances_table, auc_results_single])\n",
    "    \n",
    "    print(\"******************* FINISHED *******************\")\n",
    "    print(\"\\n\")\n",
    "    print(balance_ratios.describe())\n",
    "    \n",
    "    # Set variables used for naming the results files\n",
    "    if TRAIN_ON_SUM:\n",
    "        train = \"sum_\"\n",
    "    else: train = \"full_\"\n",
    "    if SEPARATE_CLASSIFIER:\n",
    "        sep_class = \"sep_\"\n",
    "    else: sep_class = \"same_\"\n",
    "    if OVERSAMPLE and UNDERSAMPLE:\n",
    "        print(\"CAN'T OVER AND UNDERSAMPLE AT THE SAME TIME\")\n",
    "        raise()\n",
    "    if OVERSAMPLE:\n",
    "        samp_ratio = \"OVER_\" + str(SAMPLING_RATIO)\n",
    "    elif UNDERSAMPLE:\n",
    "        samp_ratio = \"UNDER_\" + str(SAMPLING_RATIO)\n",
    "    else: samp_ratio = \"\"\n",
    "    if AL_METHOD == 5:\n",
    "        learners_qbc = '+'.join(str(x) for x in QBC_LEARNERS) + \"_\" + str(N_QBC_LEARNERS) + \"_\"\n",
    "    else: learners_qbc = \"\"\n",
    "    if AL_METHOD == 6 or AL_METHOD == 7:\n",
    "        bdwidth = \"BD_\" + str(BANDWIDTH)\n",
    "    else: bdwidth = \"\"\n",
    "    if AL_METHOD == 1:\n",
    "        weight = ''\n",
    "    else: weight = \"WF\" + str(WEIGHTING_FACTOR) + \"_\"\n",
    "    if OLD_DATA:\n",
    "        old = \"OLD_\"\n",
    "    else: old = \"\"\n",
    "    if time_point == None:\n",
    "        time_point_test = \"\"\n",
    "    elif time_point == 'all': \n",
    "        time_point_test = 'all_time_points_'\n",
    "    else: time_point_test = str(time_point) + \"_\"\n",
    "        \n",
    "    string = AL_switcher.get(AL_METHOD).__name__ + \"_\" + weight + old + bdwidth + learners_qbc + sep_class + train + \"maj_\" + samp_ratio + str(N_QUERIES) + \"_\" + time_point_test + \"_new\"\n",
    "    measure_names = ['F1', 'Recall', 'Precision', \"Selected Label Ratio\", \"AUC\", \"Feature Importance Consumer\", \"Feature Importance Producer\"]\n",
    "    measure_names = measure_names [:len(all_results)]\n",
    "    \n",
    "    plot_importance(feat_importance_cons, string, save = SAVEFIGS, cons = True)\n",
    "    if SEPARATE_CLASSIFIER:\n",
    "        plot_importance(feat_importance_prod, string, save = SAVEFIGS, cons = False)\n",
    "    \n",
    "    for result, measure_name in zip(all_results, measure_names):\n",
    "        result.describe()\n",
    "        plot_results(result, measure_name, False, string, save = SAVEFIGS)\n",
    "\n",
    "    if not TRAIN_ON_SUM:\n",
    "        string2 = AL_switcher.get(AL_METHOD).__name__ + \"_\"  + weight + old + bdwidth + learners_qbc + sep_class + train + \"single_\" + samp_ratio + str(N_QUERIES)\n",
    "        for result, measure_name in zip(all_results_single, measure_names):\n",
    "            result.describe()\n",
    "            plot_results(result, measure_name, True, string2, save = SAVEFIGS)\n",
    "    \n",
    "    if SAVERATIO:\n",
    "        np.savetxt(\"../Figures/\" + string  + \".txt\", balance_ratios.describe(), delimiter=', ', fmt='%1.4f')\n",
    "        \n",
    "    if SAVERESULTS and TRAIN_ON_SUM:\n",
    "        for result, measure_name in zip(all_results, measure_names):\n",
    "            result.to_pickle(\"../Results/\" + string + \"_\" + measure_name + \".pkl\")    \n",
    "        trajectory_selection_frequencies.to_pickle(\"../Results/\" + string + \"_freq.pkl\")\n",
    "        \n",
    "        feat_importance_cons.to_pickle(\"../Results/\" + string + \"_feat_imp_cons\" + \".pkl\")\n",
    "        if SEPARATE_CLASSIFIER:\n",
    "            feat_importance_prod.to_pickle(\"../Results/\" + string + \"_feat_imp_prod\" + \".pkl\")\n",
    "            \n",
    "    if SAVERESULTS and not TRAIN_ON_SUM:\n",
    "        for result, measure_name in zip(all_results, measure_names):\n",
    "            result.to_pickle(\"../Results/\" + string + \"_\" + measure_name + \".pkl\")    \n",
    "        trajectory_selection_frequencies.to_pickle(\"../Results/\" + string + \"_freq.pkl\")\n",
    "        \n",
    "        for result, measure_name in zip(all_results_single, measure_names):\n",
    "            result.to_pickle(\"../Results/\" + string2 + \"_\" + measure_name + \".pkl\")   \n",
    "        \n",
    "        feat_importance_cons.to_pickle(\"../Results/\" + string + \"_feat_imp_cons\" + \".pkl\")\n",
    "        if SEPARATE_CLASSIFIER:\n",
    "            feat_importance_prod.to_pickle(\"../Results/\" + string + \"_feat_imp_prod\" + \".pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for plotting the saved results as figures. \n",
    "def plot_results(results, measure_name, single, name, save = False):\n",
    "    mean_performance = results.describe().loc[['mean'], :].to_numpy()[0]\n",
    "    lower_quartiles = results.describe().loc[['25%'], :].to_numpy()[0]\n",
    "    upper_quartiles = results.describe().loc[['75%'], :].to_numpy()[0]\n",
    "    medians = results.describe().loc[['50%'], :].to_numpy()[0]\n",
    "\n",
    "    quartiles = list(zip(lower_quartiles,upper_quartiles))\n",
    "\n",
    "    # Plot our performance over time.\n",
    "    fig, ax = plt.subplots(figsize=(8.5, 6), dpi=130)\n",
    "\n",
    "    ax.plot(mean_performance)\n",
    "    ax.scatter(range(len(mean_performance)), mean_performance, s=13,c=\"blue\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "    if measure_name == \"Selected Label Ratio\":\n",
    "        ax.set_ylim(bottom=0, top = 1, auto=False)\n",
    "    else:\n",
    "        \tax.set_ylim(bottom=0.4, top = 1, auto=False) # bottom=0, top=1\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_title('Incremental Classification ' + measure_name + \" \" + AL_switcher.get(AL_METHOD).__name__)\n",
    "    ax.set_xlabel('Query iteration')\n",
    "    ax.set_ylabel('Classification ' + measure_name)\n",
    "#     ax.legend(loc=\"lower right\")\n",
    "\n",
    "    if measure_name == 'AUC':\n",
    "        x = range(len(mean_performance))\n",
    "        x = x[1:]\n",
    "        y = mean_performance\n",
    "        rand_predict = mean_performance[0]\n",
    "        y = mean_performance[1:]\n",
    "        \n",
    "        x = np.log2(x)\n",
    "        A=trapz(y)\n",
    "        Arand = rand_predict * x[-1]\n",
    "        Amax = x[-1]\n",
    "        \n",
    "        global_score = (A-Arand)/(Amax-Arand)\n",
    "        \n",
    "        print(\"ALC is: \", global_score)\n",
    "        \n",
    "        if save:\n",
    "            string = \"../Figures/\" + name + \"_\" + \"ALC\" + \".txt\"\n",
    "            text_file = open(string, \"w\")\n",
    "            n = text_file.write(str(global_score))\n",
    "            text_file.close()\n",
    "\n",
    "    if measure_name != \"Selected Label Ratio\":\n",
    "        plt.plot((range(len(mean_performance)),range(len(mean_performance))),([i for (i,j) in quartiles], [j for (i,j) in quartiles]),c='black')\n",
    "        plt.plot(range(len(mean_performance)), [i for (i,j) in quartiles], '_', markersize = 6,c='blue')\n",
    "        plt.plot(range(len(mean_performance)), [j for (i,j) in quartiles], '_', markersize = 6,c='blue')\n",
    "\n",
    "    fig.subplots_adjust(left=0.08, right=0.98, bottom=0.05, top=0.9,\n",
    "                        hspace=0.4, wspace=0.3)\n",
    "    if save:\n",
    "        string = \"../Figures/\" + name + \"_\" + measure_name + \".png\"\n",
    "        plt.savefig(string, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for plotting feature importances over the course of training for the different sizes of sliding windows and the base features.\n",
    "def plot_importance(importances, string, save = False, cons=True):\n",
    "    timeframes = [\"base\", \"expanding\", \"10 minutes\", \"60 minutes\"]\n",
    "    timeframe_start_indices = [1, 7, 39, 71, len(importances.iloc[0,0])]\n",
    "    for frame_name, frame_num in zip(timeframes, range(len(timeframes))):\n",
    "        feature_names = looping_sum.columns[looping_sum.columns != target]\n",
    "        feature_names = feature_names[timeframe_start_indices[frame_num]:timeframe_start_indices[frame_num+1]-1]\n",
    "        plt.figure()\n",
    "        fig, ax = plt.subplots(figsize=(8.5, 6), dpi=130)\n",
    "        colors = cm.rainbow(np.linspace(0,1,len(feature_names))) # gist_ncar\n",
    "\n",
    "        i = -1\n",
    "        for feat, color in zip(range(timeframe_start_indices[frame_num],timeframe_start_indices[frame_num+1]-1), colors):\n",
    "            i += 1\n",
    "            one_feat_importance = importances.applymap(lambda x: x[feat], na_action = 'ignore')\n",
    "            feature_name = feature_names[i]\n",
    "            \n",
    "            mean_importance = one_feat_importance.describe().loc[['mean'], :].to_numpy()[0]\n",
    "            \n",
    "            # Interquartile ranges not shown here due to messy graphs, but this can simply be uncommented.\n",
    "    #         lower_quartiles = one_feat_importance.describe().loc[['25%'], :].to_numpy()[0]\n",
    "    #         upper_quartiles = one_feat_importance.describe().loc[['75%'], :].to_numpy()[0]\n",
    "    #         medians = one_feat_importance.describe().loc[['50%'], :].to_numpy()[0]\n",
    "    \n",
    "            ax.plot(mean_importance,c=color)\n",
    "            ax.scatter(range(len(mean_importance)), mean_importance, s=13, marker = \"\")\n",
    "            ax.annotate(xy=(range(len(mean_importance))[-1], mean_importance[-1]), xytext=(5,0), textcoords='offset points', text=feature_name, va='center', size = 7)\n",
    "\n",
    "        title = string.split(\"_\")[0] + \"_\" + string.split(\"_\")[1] + \"_\" + string.split(\"_\")[2]\n",
    "\n",
    "        ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=5, integer=True))\n",
    "        ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=10))\n",
    "        ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=1))\n",
    "\n",
    "    #     ax.set_ylim(bottom=0, top=1)\n",
    "        ax.set_ylim(auto=True)\n",
    "        ax.grid(True)\n",
    "\n",
    "        ax.set_title('Feature Importances ' + title + \"_\" + timeframes[frame_num])\n",
    "        ax.set_xlabel('Query iteration')\n",
    "        ax.set_ylabel('Feature Importance ')\n",
    "        ax.legend(feature_names, bbox_to_anchor=(1.2, 1))\n",
    "        \n",
    "        fig.subplots_adjust(left=0.08, right=0.98, bottom=0.05, top=0.9,\n",
    "                            hspace=0.4, wspace=0.3)\n",
    "\n",
    "        if save:\n",
    "            if cons:\n",
    "                cons_or_prod = \"cons_\"\n",
    "            else:\n",
    "                cons_or_prod = \"prod_\"\n",
    "            filename = \"../Figures/\" + string + \"_\" + cons_or_prod + timeframes[frame_num] + \".png\"\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'looping_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-beed04bd915a>\u001b[0m in \u001b[0;36mrun_test\u001b[1;34m(k_, execs_, n_queries_, n_init_, train_sum_, sep_class_, ml_method_, ml_sep_method_, al_method_, qbc_learners_, n_qbc_learners_, weighting_factor_, save_figs_, save_ratio_, save_results_, time_point, bandwidth_, pal_priors, sc_pca_)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Keep track of selection frequencies of individual trajectories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mtrajectory_selection_frequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_QUERIES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlooping_sum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Compute weighting factors for when instance weighting is selected.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'looping_sum' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # # random sampling on summarized dataset\n",
    "# set_settings(k_ = 5, execs_ = 20, n_queries_ = 40, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # # # uncertainty sampling on summarized dataset\n",
    "# set_settings(k_ = 5, execs_ = 1, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # # # Density sampling on summarized dataset\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # # # PAL sampling on summarized dataset\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # # # random sampling on full dataset\n",
    "# set_settings(k_ = 5, execs_ = 2, n_queries_ = 100, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # # # uncertainty sampling on full dataset\n",
    "# set_settings(k_ = 5, execs_ = 2, n_queries_ = 100, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # # # Density sampling on full dataset\n",
    "# set_settings(k_ = 5, execs_ = 2, n_queries_ = 100, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # # # PAL sampling on full dataset\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 4, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 5, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 4, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 5, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [5], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [5], n_qbc_learners_ = 4, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [5], n_qbc_learners_ = 5, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 1, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 2, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,5], n_qbc_learners_ = 1, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,5], n_qbc_learners_ = 2, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,5], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3,5], n_qbc_learners_ = 1, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3,5], n_qbc_learners_ = 2, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3,5], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,5], n_qbc_learners_ = 1, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,5], n_qbc_learners_ = 2, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,5], n_qbc_learners_ = 3, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,5], n_qbc_learners_ = 5, save_figs_ = True, save_ratio_ = True)\n",
    "# run_test()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# test_weights = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "# # # uncertainty sampling on summarized dataset\n",
    "# for test_weight in test_weights:\n",
    "#     set_settings(k_ = 5, execs_ = 20, n_queries_ = 40, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#                  ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], weighting_factor_ = test_weight, n_qbc_learners_ = 4, \\\n",
    "#                  save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "#     run_test()\n",
    "\n",
    "# set_settings(k_ = 5, execs_ = 20, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], weighting_factor_ = 0, n_qbc_learners_ = 4, \\\n",
    "#              save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# test_weights = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "# # # pal sampling on summarized dataset\n",
    "# for test_weight in test_weights:\n",
    "#     set_settings(k_ = 5, execs_ = 20, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#                  ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], weighting_factor_ = test_weight, n_qbc_learners_ = 4, \\\n",
    "#                  save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "#     run_test()\n",
    "\n",
    "# test_weights = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "# # # xpal sampling on summarized dataset\n",
    "# for test_weight in test_weights:\n",
    "#     set_settings(k_ = 5, execs_ = 20, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#                  ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], weighting_factor_ = test_weight, n_qbc_learners_ = 4, \\\n",
    "#                  save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "#     run_test()\n",
    "\n",
    "# test_weights = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "# # # density sampling on summarized dataset\n",
    "# for test_weight in test_weights:\n",
    "#     set_settings(k_ = 5, execs_ = 20, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#                  ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], weighting_factor_ = test_weight, n_qbc_learners_ = 4, \\\n",
    "#                  save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "#     run_test()\n",
    "\n",
    "# Quick testing\n",
    "# set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 5, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0.8, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test()\n",
    "\n",
    "# # bandwidth testing\n",
    "# bandwidths = [0.01, 1.5, 2, 2.5, 3, 3.5, 10] # doesn't seem to change anything at all\n",
    "# for band in bandwidths:\n",
    "#     set_settings(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#                  ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#                  weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, bandwidth_ = band)\n",
    "#     run_test()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "# run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # Testing performance at different time points for random sampling\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "# # run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "# #              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "# #              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = \"all\")\n",
    "\n",
    "# # # Testing performance at different time points for uncertainty sampling\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "\n",
    "# run_test(k_ = 5, execs_ = 10, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = \"all\")\n",
    "\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = False, save_ratio_ = False, save_results_ = False, time_point = 20, pal_priors = 1)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = False, save_ratio_ = False, save_results_ = False, time_point = None, pal_priors = [0.5,10])\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = False, save_ratio_ = False, save_results_ = False, time_point = None, pal_priors = [10,0.5]) #  best results [10,0.5]\n",
    "\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = False, save_ratio_ = False, save_results_ = False, time_point = None, bandwidth_ = 0.1, pal_priors = [10,0.5]) #  best results [10,0.5]\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = False, save_ratio_ = False, save_results_ = False, time_point = None, bandwidth_ = 0.3, pal_priors = [10,0.5]) #  best results [10,0.5]\n",
    "\n",
    "# run_test(k_ = 5, execs_ = 1, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = False, save_ratio_ = False, save_results_ = False, time_point = 25) #  best results [10,0.5]\n",
    "\n",
    "# # # Testing performance at different time points for random sampling\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 1, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "\n",
    "# # # Testing performance at different time points for uncertainty sampling\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 2, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "\n",
    "# # # Testing performance at different time points for density-weighted sampling\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "\n",
    "run_test(k_ = 5, execs_ = 3, n_queries_ = 80, n_init_ = 10, train_sum_ = False, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 3, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "\n",
    "# # # Testing performance at different time points for qbc sampling\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "\n",
    "run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "             ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "             weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,1], n_qbc_learners_ = 8, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "\n",
    "# # # Testing performance at different time points for pal sampling\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 6, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "\n",
    "# # # Testing performance at different time points for xpal sampling\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 10)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 16)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 20)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 25)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 30)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 35)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = 40)\n",
    "# run_test(k_ = 5, execs_ = 30, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = False, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 7, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 2, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 3, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 5, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 6, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 7, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2], n_qbc_learners_ = 8, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 2, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 3, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 5, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 6, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 7, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3], n_qbc_learners_ = 8, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [1], n_qbc_learners_ = 2, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [1], n_qbc_learners_ = 3, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [1], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [1], n_qbc_learners_ = 5, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [1], n_qbc_learners_ = 6, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [1], n_qbc_learners_ = 7, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [1], n_qbc_learners_ = 8, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 1, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 2, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 3, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,1], n_qbc_learners_ = 1, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,1], n_qbc_learners_ = 2, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,1], n_qbc_learners_ = 3, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,1], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3,1], n_qbc_learners_ = 1, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3,1], n_qbc_learners_ = 2, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3,1], n_qbc_learners_ = 3, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [3,1], n_qbc_learners_ = 4, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,1], n_qbc_learners_ = 1, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,1], n_qbc_learners_ = 2, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n",
    "# run_test(k_ = 5, execs_ = 5, n_queries_ = 100, n_init_ = 10, train_sum_ = True, sep_class_ = True, \\\n",
    "#              ml_method_ = 3, ml_sep_method_ = 3, al_method_ = 5, qbc_learners_ = [2,3,1], n_qbc_learners_ = 3, \\\n",
    "#              weighting_factor_ = 0, save_figs_ = True, save_ratio_ = True, save_results_ = True, time_point = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
